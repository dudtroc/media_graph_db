#!/usr/bin/env python3
"""
ì˜¬ë°”ë¥¸ ë…¸ë“œ ìˆœì„œ ë¹„êµ - data2ì˜ storesì—ì„œ node_type ì¶”ì¶œ
"""

import torch
from pathlib import Path

def compare_correct_node_order(data2_file: Path, data_backup_file: Path) -> dict:
    """ì˜¬ë°”ë¥¸ ë°©ë²•ìœ¼ë¡œ ë…¸ë“œ ìˆœì„œ ë¹„êµ"""
    try:
        # data2 íŒŒì¼ ë¡œë“œ
        data2_content = torch.load(data2_file, map_location='cpu', weights_only=False)
        data2_data = data2_content['data']
        data2_path = data2_content.get('path', '')
        
        # data2ì—ì„œ node_type ì¶”ì¶œ (storesì—ì„œ)
        data2_node_types = data2_data.stores[0]['node_type'].tolist()
        
        # data_backup íŒŒì¼ ë¡œë“œ
        data_backup_content = torch.load(data_backup_file, map_location='cpu', weights_only=False)
        data_backup_z = data_backup_content['z']
        data_backup_orig_id = data_backup_content.get('orig_id', [])
        data_backup_node_type = data_backup_content.get('node_type', [])
        data_backup_path = data_backup_content.get('path', '')
        
        # ê¸°ë³¸ ì •ë³´
        analysis = {
            'file1': str(data2_file),
            'file2': str(data_backup_file),
            'data2_embedding_count': len(data2_data.x),
            'data_backup_embedding_count': len(data_backup_z),
            'path_match': data2_path == data_backup_path,
            'data2_path': data2_path,
            'data_backup_path': data_backup_path
        }
        
        # ì„ë² ë”© ê°œìˆ˜ ë¹„êµ
        if len(data2_data.x) != len(data_backup_z):
            analysis['error'] = f"ì„ë² ë”© ê°œìˆ˜ ë‹¤ë¦„: data2 {len(data2_data.x)} vs data_backup {len(data_backup_z)}"
            return analysis
        
        # data2ì˜ ë…¸ë“œ ì •ë³´ (node_typeë§Œ ì‚¬ìš©)
        data2_node_info = []
        for i, node_type in enumerate(data2_node_types):
            node_type_map = {0: 'unknown', 1: 'object', 2: 'event', 3: 'spatial'}
            node_type_name = node_type_map.get(node_type, 'unknown')
            data2_node_info.append(f"{node_type_name}_{i}")
        
        # data_backupì˜ ë…¸ë“œ ì •ë³´ (orig_idì™€ node_type ì‚¬ìš©)
        data_backup_node_info = []
        for i, orig_id in enumerate(data_backup_orig_id):
            node_type_idx = data_backup_node_type[i] if i < len(data_backup_node_type) else 0
            node_type_map = {0: 'unknown', 1: 'object', 2: 'event', 3: 'spatial'}
            node_type_name = node_type_map.get(node_type_idx, 'unknown')
            data_backup_node_info.append(f"{node_type_name}_{orig_id}")
        
        analysis['data2_node_info'] = data2_node_info
        analysis['data_backup_node_info'] = data_backup_node_info
        analysis['node_info_match'] = data2_node_info == data_backup_node_info
        
        # node_type ìˆœì„œë§Œ ë¹„êµ
        data2_node_types_only = data2_node_types
        data_backup_node_types_only = data_backup_node_type.tolist() if hasattr(data_backup_node_type, 'tolist') else list(data_backup_node_type)
        
        analysis['data2_node_types'] = data2_node_types_only
        analysis['data_backup_node_types'] = data_backup_node_types_only
        analysis['node_types_match'] = data2_node_types_only == data_backup_node_types_only
        
        # ìˆœì„œë³„ ë¹„êµ
        order_comparison = []
        for i in range(min(len(data2_node_info), len(data_backup_node_info))):
            order_comparison.append({
                'index': i,
                'data2': data2_node_info[i],
                'data_backup': data_backup_node_info[i],
                'data2_node_type': data2_node_types_only[i],
                'data_backup_node_type': data_backup_node_types_only[i],
                'node_type_match': data2_node_types_only[i] == data_backup_node_types_only[i],
                'full_match': data2_node_info[i] == data_backup_node_info[i]
            })
        
        analysis['order_comparison'] = order_comparison
        analysis['matching_indices'] = sum(1 for comp in order_comparison if comp['full_match'])
        analysis['node_type_matching_indices'] = sum(1 for comp in order_comparison if comp['node_type_match'])
        analysis['total_indices'] = len(order_comparison)
        
        return analysis
        
    except Exception as e:
        return {
            'file1': str(data2_file),
            'file2': str(data_backup_file),
            'error': str(e)
        }

def main():
    data2_dir = Path("/home/ktva/PROJECT/MEDIA/media-graph-db/client/data2")
    data_backup_dir = Path("/home/ktva/PROJECT/MEDIA/media-graph-db/client/data_backup")
    
    # ìƒ˜í”Œ íŒŒì¼ë“¤ë¡œ í…ŒìŠ¤íŠ¸
    sample_files = [
        "Twenty.Five.Twenty.One_EP05_visual_44444-46903_(00_30_54-00_32_36)_meta_info.pt",
        "Our.Blues_EP13_visual_27292-30176_(00_18_58-00_20_59)_meta_info.pt",
        "The.Fiery.Priest_EP01_visual_72752-77369_(00_40_27-00_43_02)_meta_info.pt"
    ]
    
    print("ğŸ” ì˜¬ë°”ë¥¸ ë…¸ë“œ ìˆœì„œ ë¹„êµ ë¶„ì„")
    print("=" * 80)
    
    for filename in sample_files:
        print(f"\níŒŒì¼: {filename}")
        print("-" * 60)
        
        data2_file = data2_dir / filename
        data_backup_file = data_backup_dir / filename
        
        if not data2_file.exists():
            print(f"âŒ data2ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filename}")
            continue
            
        if not data_backup_file.exists():
            print(f"âŒ data_backupì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filename}")
            continue
        
        analysis = compare_correct_node_order(data2_file, data_backup_file)
        
        if 'error' in analysis:
            print(f"âŒ ì˜¤ë¥˜: {analysis['error']}")
            continue
        
        print(f"ğŸ“Š ì„ë² ë”© ê°œìˆ˜: data2 {analysis['data2_embedding_count']} vs data_backup {analysis['data_backup_embedding_count']}")
        print(f"ğŸ“Š Path ì¼ì¹˜: {'âœ…' if analysis['path_match'] else 'âŒ'}")
        print(f"ğŸ“Š Node Type ìˆœì„œ ì¼ì¹˜: {'âœ…' if analysis['node_types_match'] else 'âŒ'}")
        print(f"ğŸ“Š ì „ì²´ ë…¸ë“œ ì •ë³´ ì¼ì¹˜: {'âœ…' if analysis['node_info_match'] else 'âŒ'}")
        
        if analysis['node_types_match']:
            print("âœ… Node Type ìˆœì„œê°€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!")
            print("   â†’ ì„ë² ë”©ê³¼ ë…¸ë“œì˜ ë§¤í•‘ì´ ë™ì¼í•©ë‹ˆë‹¤!")
        else:
            print(f"âš ï¸ Node Type ìˆœì„œ: {analysis['node_type_matching_indices']}/{analysis['total_indices']}ê°œ ì¼ì¹˜")
            
            # ì²˜ìŒ 10ê°œì™€ ë§ˆì§€ë§‰ 10ê°œ ë¹„êµ
            print("\nğŸ” ì²˜ìŒ 10ê°œ ë…¸ë“œ ë¹„êµ:")
            for i, comp in enumerate(analysis['order_comparison'][:10]):
                node_type_status = "âœ…" if comp['node_type_match'] else "âŒ"
                print(f"  {i:2d}: {node_type_status} data2={comp['data2_node_type']} | data_backup={comp['data_backup_node_type']}")
            
            if len(analysis['order_comparison']) > 10:
                print("\nğŸ” ë§ˆì§€ë§‰ 10ê°œ ë…¸ë“œ ë¹„êµ:")
                for i, comp in enumerate(analysis['order_comparison'][-10:], len(analysis['order_comparison'])-10):
                    node_type_status = "âœ…" if comp['node_type_match'] else "âŒ"
                    print(f"  {i:2d}: {node_type_status} data2={comp['data2_node_type']} | data_backup={comp['data_backup_node_type']}")
        
        print(f"\nğŸ“ Path ì •ë³´:")
        print(f"  data2: {analysis['data2_path']}")
        print(f"  data_backup: {analysis['data_backup_path']}")

if __name__ == "__main__":
    main()
