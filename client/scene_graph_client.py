#!/usr/bin/env python3
"""
ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í´ë¼ì´ì–¸íŠ¸
ëª¨ë“  DB API ì ‘ê·¼ ê¸°ëŠ¥ì„ í†µí•©í•œ í´ë˜ìŠ¤
"""

import os
import json
import requests
import torch
import torch.nn.functional as F
import heapq
from typing import Dict, List, Any, Optional, Tuple
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

# ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆë“¤ import
from util import VideoDataDeleter, SceneGraphDataChecker, SceneGraphAPIUploader
from util.schema_info import SchemaInfoChecker

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class SceneGraphDBClient:
    """
    ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í´ë¼ì´ì–¸íŠ¸
    
    ì´ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ í†µí•©í•©ë‹ˆë‹¤:
    - ë¹„ë””ì˜¤ ë°ì´í„° ì‚­ì œ (VideoDataDeleter)
    - ì €ì¥ëœ ë°ì´í„° í™•ì¸ (SceneGraphDataChecker)  
    - ì¥ë©´ê·¸ë˜í”„ ë°ì´í„° ì—…ë¡œë“œ (SceneGraphAPIUploader)
    - ê¸°ë³¸ì ì¸ DB API ì ‘ê·¼ ê¸°ëŠ¥
    """
    
    def __init__(self, db_api_base_url: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            db_api_base_url: API ì„œë²„ URL (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ API_URL ë˜ëŠ” http://localhost:8000)
        """
        self.db_api_base_url = db_api_base_url or os.getenv("API_URL", "http://localhost:8000")
        self.session = requests.Session()
        
        # í•˜ìœ„ í´ë¼ì´ì–¸íŠ¸ë“¤ ì´ˆê¸°í™”
        self.deleter = VideoDataDeleter(self.db_api_base_url)
        self.checker = SceneGraphDataChecker(self.db_api_base_url)
        self.uploader = SceneGraphAPIUploader(self.db_api_base_url)
        self.schema_checker = SchemaInfoChecker()
        
        print(f"ğŸŒ SceneGraphClient ì´ˆê¸°í™” ì™„ë£Œ - API URL: {self.db_api_base_url}")
    
    # ==================== ê¸°ë³¸ ì—°ê²° ë° ìƒíƒœ í™•ì¸ ====================
    
    def health_check(self) -> bool:
        """API ì„œë²„ í—¬ìŠ¤ ì²´í¬"""
        return self.checker.check_connection()
    
    def get_server_info(self) -> Dict[str, Any]:
        """ì„œë²„ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.db_api_base_url}/")
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ì„œë²„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    # ==================== ë¹„ë””ì˜¤ ê´€ë¦¬ ====================
    
    def get_videos(self) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ"""
        return self.checker.get_videos()
    
    def get_video_info(self, video_unique_id: int) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ë¹„ë””ì˜¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        return self.deleter.get_video_info(video_unique_id)
    
    def create_video(self, drama_name: str, episode_number: str, video_unique_id: int = None) -> Optional[Dict[str, Any]]:
        """ë¹„ë””ì˜¤ ìƒì„±"""
        try:
            if video_unique_id is None:
                video_unique_id = self._generate_video_id(drama_name, episode_number)
            
            video_data = {
                "video_unique_id": video_unique_id,
                "drama_name": drama_name,
                "episode_number": episode_number
            }
            
            response = self.session.post(f"{self.db_api_base_url}/videos", json=video_data)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def delete_video(self, video_unique_id: int, confirm: bool = False) -> bool:
        """ë¹„ë””ì˜¤ ë° ì—°ê²°ëœ ëª¨ë“  ë°ì´í„° ì‚­ì œ"""
        return self.deleter.delete_video(video_unique_id, confirm)
    
    def list_videos(self) -> None:
        """ë¹„ë””ì˜¤ ëª©ë¡ í‘œì‹œ"""
        self.deleter.list_videos()
    
    # ==================== ì¥ë©´ ê´€ë¦¬ ====================
    
    def get_scenes(self, video_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë¹„ë””ì˜¤ì˜ ì¥ë©´ ëª©ë¡ ì¡°íšŒ"""
        return self.checker.get_scenes(video_id)
    
    def get_scene_graph(self, scene_id: int) -> Dict[str, Any]:
        """íŠ¹ì • ì¥ë©´ì˜ ì™„ì „í•œ ê·¸ë˜í”„ ì •ë³´ ì¡°íšŒ"""
        return self.checker.get_scene_graph(scene_id)
    
    def get_scene_objects(self, scene_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì˜ ê°ì²´ ë…¸ë“œ ì¡°íšŒ"""
        return self.checker.get_objects(scene_id)
    
    def get_scene_events(self, scene_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì˜ ì´ë²¤íŠ¸ ë…¸ë“œ ì¡°íšŒ"""
        return self.checker.get_events(scene_id)
    
    def get_scene_spatial_relations(self, scene_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì˜ ê³µê°„ê´€ê³„ ì¡°íšŒ"""
        return self.checker.get_spatial_relations(scene_id)
    
    def get_scene_temporal_relations(self, scene_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì˜ ì‹œê°„ê´€ê³„ ì¡°íšŒ"""
        return self.checker.get_temporal_relations(scene_id)
    
    def get_scene_embeddings(self, scene_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì˜ ì„ë² ë”© ì •ë³´ ì¡°íšŒ"""
        return self.checker.get_embeddings(scene_id)
    
    def delete_scene_embeddings(self, scene_id: int) -> bool:
        """íŠ¹ì • ì¥ë©´ì˜ ëª¨ë“  ì„ë² ë”© ì •ë³´ ì‚­ì œ (ì‹¤ì œë¡œëŠ” ìŠ¤í‚µ - ì—…ë°ì´íŠ¸ ë¡œì§ í™œìš©)"""
        try:
            print(f"ğŸ”„ ì¥ë©´ {scene_id}ì˜ ì„ë² ë”© ë®ì–´ì“°ê¸° ì¤€ë¹„")
            
            # í•´ë‹¹ ì¥ë©´ì˜ ëª¨ë“  ì„ë² ë”© ì¡°íšŒ
            embeddings = self.get_scene_embeddings(scene_id)
            if not embeddings:
                print(f"âš ï¸ ì¥ë©´ {scene_id}ì— ê¸°ì¡´ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            print(f"â„¹ï¸ ì¥ë©´ {scene_id}ì— {len(embeddings)}ê°œì˜ ê¸°ì¡´ ì„ë² ë”©ì´ ìˆìŠµë‹ˆë‹¤.")
            print(f"â„¹ï¸ ìƒˆë¡œìš´ ì„ë² ë”©ìœ¼ë¡œ ìë™ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    # ==================== ì¥ë©´ê·¸ë˜í”„ ì—…ë¡œë“œ ====================
    
    def upload_scene_graph(self, json_file_path: str, overwrite_embeddings: bool = False) -> bool:
        """
        JSON íŒŒì¼ê³¼ ëŒ€ì‘í•˜ëŠ” PT íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ì—…ë¡œë“œ
        
        Args:
            json_file_path: JSON íŒŒì¼ ê²½ë¡œ
            overwrite_embeddings: ê¸°ì¡´ ì„ë² ë”©ì„ ë®ì–´ì“¸ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            
        Returns:
            bool: ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸš€ ì¥ë©´ê·¸ë˜í”„ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {json_file_path}")
            print("=" * 50)
            
            # 1. API ì„œë²„ í—¬ìŠ¤ ì²´í¬
            if not self.health_check():
                print("âŒ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 2. íŒŒì¼ëª… íŒŒì‹±
            file_info = self._parse_filename(os.path.basename(json_file_path))
            drama_name = file_info['drama_name']
            episode_number = file_info['episode_number']
            start_frame = file_info['start_frame']
            end_frame = file_info['end_frame']
            
            print(f"ğŸ“º ë¹„ë””ì˜¤ ì •ë³´: {drama_name} {episode_number}")
            print(f"ğŸ¬ í”„ë ˆì„ ë²”ìœ„: {start_frame}-{end_frame}")
            
            # 3. JSON íŒŒì¼ ë¡œë“œ
            scene_data = self._load_scene_graph_data(json_file_path)
            
            # 4. ëŒ€ì‘í•˜ëŠ” PT íŒŒì¼ ì°¾ê¸°
            pt_file_path = json_file_path.replace('.json', '.pt')
            if not os.path.exists(pt_file_path):
                print(f"âŒ ëŒ€ì‘í•˜ëŠ” PT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pt_file_path}")
                return False
            
            # 5. PT íŒŒì¼ ë¡œë“œ
            pt_data = self._load_pt_data(pt_file_path)
            
            # 6. ë¹„ë””ì˜¤ ìƒì„±/ì¡°íšŒ
            video_result = self.create_video(drama_name, episode_number)
            if not video_result:
                print("âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
                return False
            
            video_id = video_result.get('video_id')
            actual_video_unique_id = video_result.get('video_unique_id')
            print(f"âœ… ë¹„ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ: {drama_name} {episode_number} (ID: {video_id})")
            
            # 7. ì¥ë©´ ë©”íƒ€ë°ì´í„° ìƒì„±
            scene_meta = scene_data.get('scene_graph', {}).get('meta', {})
            scene_payload = {
                "scene_number": f"{start_frame}-{end_frame}",
                "scene_place": scene_meta.get('scene_place'),
                "scene_time": scene_meta.get('scene_time'),
                "scene_atmosphere": scene_meta.get('scene_atmosphere'),
                "start_frame": start_frame,
                "end_frame": end_frame
            }
            
            # 8. ì¥ë©´ ìƒì„± API í˜¸ì¶œ (ì„ë² ë”© ì—†ì´)
            scene_request = {
                "video_unique_id": actual_video_unique_id,
                "scene_data": scene_payload,
                "pt_data": None  # ì„ë² ë”©ì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
            }
            
            response = self.session.post(f"{self.db_api_base_url}/scenes", json=scene_request)
            response.raise_for_status()
            scene_result = response.json()
            scene_id = scene_result.get('scene_id')
            
            if not scene_id:
                print("âŒ ì¥ë©´ ìƒì„± ì‹¤íŒ¨")
                return False
            
            print(f"âœ… ì¥ë©´ ìƒì„± ì™„ë£Œ: {scene_id}")
            
            # 9. ë…¸ë“œ ë°ì´í„° ì €ì¥ (objects, events, spatial, temporal)
            self._create_nodes_from_data(scene_id, scene_data.get('scene_graph', {}), actual_video_unique_id)
            
            # 10. ì„ë² ë”© ë®ì–´ì“°ê¸° ì²˜ë¦¬
            if overwrite_embeddings:
                print("ğŸ”„ ê¸°ì¡´ ì„ë² ë”© ë®ì–´ì“°ê¸° ëª¨ë“œ")
                self.delete_scene_embeddings(scene_id)
            
            # 11. ì„ë² ë”© ë°ì´í„° ì €ì¥
            self._create_embeddings_from_pt_data(scene_id, pt_data, actual_video_unique_id)
            
            print("\n" + "=" * 50)
            print("âœ… ì¥ë©´ê·¸ë˜í”„ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
            print(f"ğŸ“º ë¹„ë””ì˜¤: {drama_name} {episode_number}")
            print(f"ğŸ­ ì¥ë©´: í”„ë ˆì„ {start_frame}-{end_frame}")
            print(f"ğŸ†” ë¹„ë””ì˜¤ ID: {video_id}, ì¥ë©´ ID: {scene_id}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def upload_scene_graph_with_pt(self, scene_data: Dict[str, Any], embedding_info: Dict[str, Any], 
                                 video_unique_id: int, drama_name: str, episode_number: str,
                                 start_frame: int, end_frame: int) -> bool:
        """
        ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ì™€ ì„ë² ë”© ì •ë³´ë¥¼ ì§ì ‘ ì…ë ¥ë°›ì•„ ì—…ë¡œë“œ
        
        Args:
            scene_data: ì¥ë©´ê·¸ë˜í”„ JSON ë°ì´í„°
            embedding_info: ì„ë² ë”© ì •ë³´ {'node_info': [...], 'node_embeddings': [...]}
            video_unique_id: ë¹„ë””ì˜¤ ê³ ìœ  ID
            drama_name: ë“œë¼ë§ˆëª…
            episode_number: ì—í”¼ì†Œë“œ ë²ˆí˜¸
            start_frame: ì‹œì‘ í”„ë ˆì„
            end_frame: ì¢…ë£Œ í”„ë ˆì„
        
        Returns:
            bool: ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print("ğŸš€ ì¥ë©´ê·¸ë˜í”„ ë°ì´í„° ì§ì ‘ ì—…ë¡œë“œ ì‹œì‘")
            print("=" * 50)
            
            # 1. API ì„œë²„ í—¬ìŠ¤ ì²´í¬
            if not self.health_check():
                print("âŒ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 2. ë¹„ë””ì˜¤ ìƒì„±/ì¡°íšŒ
            video_result = self.create_video(drama_name, episode_number, video_unique_id)
            if not video_result:
                print("âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
                return False
            
            video_id = video_result.get('video_id')
            actual_video_unique_id = video_result.get('video_unique_id')
            print(f"âœ… ë¹„ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ: {drama_name} {episode_number} (ID: {video_id})")
            
            # 3. ì¥ë©´ ë©”íƒ€ë°ì´í„° ìƒì„± (ì„ë² ë”© ì œì™¸)
            scene_meta = scene_data.get('scene_graph', {}).get('meta', {})
            scene_payload = {
                "scene_number": f"{start_frame}-{end_frame}",
                "scene_place": scene_meta.get('scene_place'),
                "scene_time": scene_meta.get('scene_time'),
                "scene_atmosphere": scene_meta.get('scene_atmosphere'),
                "start_frame": start_frame,
                "end_frame": end_frame
            }
            
            # ì¥ë©´ ìƒì„± API í˜¸ì¶œ (ì„ë² ë”© ì—†ì´)
            scene_request = {
                "video_unique_id": actual_video_unique_id,
                "scene_data": scene_payload,
                "pt_data": None  # ì„ë² ë”©ì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
            }
            
            response = self.session.post(f"{self.db_api_base_url}/scenes", json=scene_request)
            response.raise_for_status()
            scene_result = response.json()
            scene_id = scene_result.get('scene_id')
            
            if not scene_id:
                print("âŒ ì¥ë©´ ìƒì„± ì‹¤íŒ¨")
                return False
            
            print(f"âœ… ì¥ë©´ ìƒì„± ì™„ë£Œ: {scene_id}")
            
            # 4. ë…¸ë“œ ë°ì´í„° ì €ì¥ (objects, events, spatial, temporal)
            self._create_nodes_from_data(scene_id, scene_data.get('scene_graph', {}), actual_video_unique_id)
            
            # 5. ì„ë² ë”© ë°ì´í„° ì €ì¥
            self._create_embeddings_from_info(scene_id, embedding_info, actual_video_unique_id)
            
            print("\n" + "=" * 50)
            print("âœ… ì¥ë©´ê·¸ë˜í”„ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
            print(f"ğŸ“º ë¹„ë””ì˜¤: {drama_name} {episode_number}")
            print(f"ğŸ­ ì¥ë©´: í”„ë ˆì„ {start_frame}-{end_frame}")
            print(f"ğŸ†” ë¹„ë””ì˜¤ ID: {video_id}, ì¥ë©´ ID: {scene_id}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    # ==================== ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œ ====================
    
    def _parse_filename(self, filename: str) -> Dict[str, Any]:
        """
        íŒŒì¼ëª…ì—ì„œ ë¹„ë””ì˜¤ì™€ ì¥ë©´ ì •ë³´ ì¶”ì¶œ
        
        ì˜ˆì‹œ: "Hospital.Playlist_EP01_visual_181-455_(00_00_06-00_00_15)_meta_info.json"
        """
        import re
        
        print(f"ğŸ“ íŒŒì¼ëª… íŒŒì‹±: {filename}")
        
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ (ê´„í˜¸ì™€ ë²ˆí˜¸ í¬í•¨ ì²˜ë¦¬)
        match = re.match(r'(.+)_(.+)_visual_(\d+)-(\d+)_.*_meta_info(?: \(\d+\))?\.json', filename)
        if not match:
            raise ValueError(f"íŒŒì¼ëª… í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {filename}")
        
        drama_name, episode_number, start_frame, end_frame = match.groups()
        
        result = {
            'drama_name': drama_name,
            'episode_number': episode_number,
            'start_frame': int(start_frame),
            'end_frame': int(end_frame)
        }
        
        print(f"âœ… íŒŒì‹± ê²°ê³¼: {result}")
        return result
    
    def _load_scene_graph_data(self, file_path: str) -> Dict[str, Any]:
        """JSON íŒŒì¼ì—ì„œ ì¥ë©´ ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“– JSON íŒŒì¼ ë¡œë“œ: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            return data
        except Exception as e:
            print(f"âŒ JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_pt_data(self, file_path: str) -> Dict[str, Any]:
        """PT íŒŒì¼ì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“– PT íŒŒì¼ ë¡œë“œ: {file_path}")
        
        try:
            import torch
            import numpy as np
            pt_data = torch.load(file_path, map_location='cpu')
            
            print(f"âœ… PT ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print(f"ğŸ“Š PT íŒŒì¼ í‚¤ë“¤: {list(pt_data.keys())}")
            
            # PyTorch í…ì„œë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            processed_data = {}
            for key, value in pt_data.items():
                if isinstance(value, torch.Tensor):
                    # í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ í›„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    processed_data[key] = value.numpy().tolist()
                elif isinstance(value, (list, tuple)):
                    # ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œì˜ ê° ìš”ì†Œê°€ í…ì„œì¸ì§€ í™•ì¸
                    processed_list = []
                    for item in value:
                        if isinstance(item, torch.Tensor):
                            processed_list.append(item.numpy().tolist())
                        else:
                            processed_list.append(item)
                    processed_data[key] = processed_list
                else:
                    processed_data[key] = value
            
            if 'z' in processed_data:
                embeddings = processed_data['z']
                if isinstance(embeddings, list) and len(embeddings) > 0:
                    print(f"âœ… ì„ë² ë”© ë²¡í„° ì°¨ì›: {len(embeddings)} x {len(embeddings[0])}")
                else:
                    print(f"âœ… ì„ë² ë”© íƒ€ì…: {type(embeddings)}")
            
            return processed_data
        except Exception as e:
            print(f"âŒ PT íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_embeddings_from_pt_data(self, scene_id: int, pt_data: Dict[str, Any], video_unique_id: int) -> None:
        """PT ë°ì´í„°ì—ì„œ ì„ë² ë”© ì •ë³´ë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥"""
        print(f"ğŸ”— PT ë°ì´í„°ì—ì„œ ì„ë² ë”© ìƒì„± ì‹œì‘")
        
        try:
            if 'z' not in pt_data or 'orig_id' not in pt_data:
                print("âŒ PT ë°ì´í„°ì— ì„ë² ë”© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            embeddings = pt_data['z']
            orig_ids = pt_data['orig_id']
            node_types = pt_data.get('node_type', [])
            
            if len(embeddings) != len(orig_ids):
                print(f"âŒ ì„ë² ë”©ê³¼ orig_id ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: {len(embeddings)} vs {len(orig_ids)}")
                return
            
            # ID 0ì€ íŠ¹ë³„í•œ ë…¸ë“œì´ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            for i, orig_id in enumerate(orig_ids):
                if orig_id == 0:
                    continue
                
                # ë…¸ë“œ íƒ€ì… ê²°ì •
                if i < len(node_types):
                    node_type_idx = node_types[i]
                    if node_type_idx == 0:
                        continue
                    elif node_type_idx == 1:
                        node_type = 'object'
                    elif node_type_idx == 2:
                        node_type = 'event'
                    elif node_type_idx == 3:
                        node_type = 'spatial'
                    else:
                        continue
                else:
                    # node_type ì •ë³´ê°€ ì—†ìœ¼ë©´ orig_idë¡œ ì¶”ì •
                    if 1000 <= orig_id < 2000:
                        node_type = 'object'
                    elif 2000 <= orig_id < 3000:
                        node_type = 'temporal'
                    elif 3000 <= orig_id < 4000:
                        node_type = 'event'
                    elif 11000 <= orig_id < 12000:
                        node_type = 'spatial'
                    else:
                        continue
                
                # ì‹¤ì œ node_id ìƒì„±: {video_unique_id}_{scene_id}_{node_type}_{orig_id}
                actual_node_id = f"{video_unique_id}_{scene_id}_{node_type}_{orig_id}"
                
                # ì„ë² ë”© ë²¡í„° ê°€ì ¸ì˜¤ê¸°
                embedding_vector = embeddings[i]
                
                # ì„ë² ë”© ë°ì´í„° ì €ì¥
                embedding_data = {
                    "node_id": actual_node_id,
                    "node_type": node_type,
                    "embedding": embedding_vector
                }
                
                # ì„ë² ë”© ì €ì¥ API í˜¸ì¶œ
                response = self.session.post(f"{self.db_api_base_url}/embeddings", json=embedding_data)
                response.raise_for_status()
                
                print(f"  âœ… ì„ë² ë”© ì €ì¥: {node_type}_{orig_id} -> {actual_node_id}")
            
            print(f"âœ… PT ë°ì´í„°ì—ì„œ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len([id for id in orig_ids if id != 0])}ê°œ")
            
        except Exception as e:
            print(f"âŒ PT ë°ì´í„° ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _create_nodes_from_data(self, scene_id: int, scene_graph: Dict[str, Any], video_unique_id: int) -> None:
        """ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ì—ì„œ ë…¸ë“œë“¤ì„ ìƒì„±"""
        print(f"ğŸ”— ë…¸ë“œ ë°ì´í„° ì €ì¥ ì‹œì‘: Scene ID {scene_id}")
        
        try:
            # 1. ê°ì²´ ë…¸ë“œ ì €ì¥
            objects = scene_graph.get('objects', [])
            if objects:
                self._create_objects_from_data(scene_id, objects, video_unique_id)
            
            # 2. ì´ë²¤íŠ¸ ë…¸ë“œ ì €ì¥
            events = scene_graph.get('events', [])
            if events:
                self._create_events_from_data(scene_id, events, video_unique_id)
            
            # 3. ê³µê°„ ê´€ê³„ ì €ì¥
            spatial = scene_graph.get('spatial', [])
            if spatial:
                self._create_spatial_from_data(scene_id, spatial, video_unique_id)
            
            # 4. ì‹œê°„ ê´€ê³„ ì €ì¥
            temporal = scene_graph.get('temporal', [])
            if temporal:
                self._create_temporal_from_data(scene_id, temporal, video_unique_id)
            
            print(f"âœ… ëª¨ë“  ë…¸ë“œ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë…¸ë“œ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_objects_from_data(self, scene_id: int, objects: List[Dict[str, Any]], video_unique_id: int) -> None:
        """ê°ì²´ ë…¸ë“œ ë°ì´í„° ì €ì¥"""
        print(f"ğŸ‘¥ ê°ì²´ ë…¸ë“œ ì €ì¥: {len(objects)}ê°œ")
        
        for obj in objects:
            try:
                original_object_id = obj.get('object_id')
                new_object_id = f"{video_unique_id}_{scene_id}_object_{original_object_id}"
                
                # labelì´ ì—†ìœ¼ë©´ type ofë¥¼ ì‚¬ìš©
                label = obj.get('label')
                if not label:
                    label = obj.get('type of', 'unknown')
                
                object_data = {
                    "scene_id": scene_id,
                    "object_id": new_object_id,
                    "super_type": obj.get('super_type', 'unknown'),
                    "type_of": obj.get('type of', 'unknown'),
                    "label": label,
                    "attributes": obj.get('attributes', {})
                }
                
                response = self.session.post(f"{self.db_api_base_url}/objects", json=object_data)
                response.raise_for_status()
                print(f"  âœ… ê°ì²´ ì €ì¥: {obj.get('label')} (ID: {new_object_id})")
                
            except Exception as e:
                print(f"  âŒ ê°ì²´ ì €ì¥ ì‹¤íŒ¨: {obj.get('label')} - {e}")
    
    def _create_events_from_data(self, scene_id: int, events: List[Dict[str, Any]], video_unique_id: int) -> None:
        """ì´ë²¤íŠ¸ ë…¸ë“œ ë°ì´í„° ì €ì¥"""
        print(f"ğŸ¬ ì´ë²¤íŠ¸ ë…¸ë“œ ì €ì¥: {len(events)}ê°œ")
        
        for i, event in enumerate(events):
            try:
                original_event_id = event.get('event_id', f"EVT_{i}")
                new_event_id = f"{video_unique_id}_{scene_id}_event_{original_event_id}"
                
                # subject_idì™€ object_idë¥¼ ìƒˆë¡œìš´ ê°ì²´ IDë¡œ ë§¤í•‘
                subject_id = str(event.get('subject', ''))
                object_id = str(event.get('object', '')) if event.get('object') else None
                
                # ê°ì²´ ID ë§¤í•‘ (ê°„ë‹¨í•œ ë§¤í•‘ ë¡œì§)
                if subject_id.isdigit():
                    subject_id = f"{video_unique_id}_{scene_id}_object_{subject_id}"
                if object_id and object_id.isdigit():
                    object_id = f"{video_unique_id}_{scene_id}_object_{object_id}"
                
                event_data = {
                    "scene_id": scene_id,
                    "event_id": new_event_id,
                    "subject_id": subject_id,
                    "verb": event.get('verb', 'unknown_action'),
                    "object_id": object_id,
                    "attributes": {"attribute": event.get('attribute', '')}
                }
                
                response = self.session.post(f"{self.db_api_base_url}/events", json=event_data)
                response.raise_for_status()
                print(f"  âœ… ì´ë²¤íŠ¸ ì €ì¥: {event.get('verb')} (ID: {new_event_id})")
                
            except Exception as e:
                print(f"  âŒ ì´ë²¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {event.get('verb')} - {e}")
    
    def _create_spatial_from_data(self, scene_id: int, spatial: List[Dict[str, Any]], video_unique_id: int) -> None:
        """ê³µê°„ ê´€ê³„ ë°ì´í„° ì €ì¥"""
        print(f"ğŸ“ ê³µê°„ ê´€ê³„ ì €ì¥: {len(spatial)}ê°œ")
        
        for i, rel in enumerate(spatial):
            try:
                original_spatial_id = rel.get('spatial_id', f"SPAT_{i}")
                new_spatial_id = f"{video_unique_id}_{scene_id}_spatial_{original_spatial_id}"
                
                # subject_idì™€ object_idë¥¼ ìƒˆë¡œìš´ ê°ì²´ IDë¡œ ë§¤í•‘
                subject_id = str(rel.get('subject', ''))
                object_id = str(rel.get('object', ''))
                
                if subject_id.isdigit():
                    subject_id = f"{video_unique_id}_{scene_id}_object_{subject_id}"
                if object_id.isdigit():
                    object_id = f"{video_unique_id}_{scene_id}_object_{object_id}"
                
                spatial_data = {
                    "scene_id": scene_id,
                    "spatial_id": new_spatial_id,
                    "subject_id": subject_id,
                    "predicate": rel.get('predicate', 'unknown_relation'),
                    "object_id": object_id
                }
                
                response = self.session.post(f"{self.db_api_base_url}/spatial", json=spatial_data)
                response.raise_for_status()
                print(f"  âœ… ê³µê°„ ê´€ê³„ ì €ì¥: {rel.get('predicate')} (ID: {new_spatial_id})")
                
            except Exception as e:
                print(f"  âŒ ê³µê°„ ê´€ê³„ ì €ì¥ ì‹¤íŒ¨: {rel.get('predicate')} - {e}")
    
    def _create_temporal_from_data(self, scene_id: int, temporal: List[Dict[str, Any]], video_unique_id: int) -> None:
        """ì‹œê°„ ê´€ê³„ ë°ì´í„° ì €ì¥"""
        print(f"â° ì‹œê°„ ê´€ê³„ ì €ì¥: {len(temporal)}ê°œ")
        
        for i, rel in enumerate(temporal):
            try:
                original_temporal_id = rel.get('temporal_id', f"TEMP_{i}")
                new_temporal_id = f"{video_unique_id}_{scene_id}_temporal_{original_temporal_id}"
                
                # subject_idì™€ object_idë¥¼ ìƒˆë¡œìš´ ì´ë²¤íŠ¸ IDë¡œ ë§¤í•‘
                subject_id = str(rel.get('subject', ''))
                object_id = str(rel.get('object', ''))
                
                if subject_id.isdigit():
                    subject_id = f"{video_unique_id}_{scene_id}_event_{subject_id}"
                if object_id.isdigit():
                    object_id = f"{video_unique_id}_{scene_id}_event_{object_id}"
                
                temporal_data = {
                    "scene_id": scene_id,
                    "temporal_id": new_temporal_id,
                    "subject_id": subject_id,
                    "predicate": rel.get('predicate', 'unknown_relation'),
                    "object_id": object_id
                }
                
                response = self.session.post(f"{self.db_api_base_url}/temporal", json=temporal_data)
                response.raise_for_status()
                print(f"  âœ… ì‹œê°„ ê´€ê³„ ì €ì¥: {rel.get('predicate')} (ID: {new_temporal_id})")
                
            except Exception as e:
                print(f"  âŒ ì‹œê°„ ê´€ê³„ ì €ì¥ ì‹¤íŒ¨: {rel.get('predicate')} - {e}")
    
    def _create_embeddings_from_info(self, scene_id: int, embedding_info: Dict[str, Any], video_unique_id: int) -> None:
        """ì„ë² ë”© ì •ë³´ì—ì„œ ì„ë² ë”© ë°ì´í„° ì €ì¥"""
        print(f"ğŸ”— ì„ë² ë”© ë°ì´í„° ì €ì¥ ì‹œì‘")
        
        try:
            node_info = embedding_info.get('node_info', [])
            node_embeddings = embedding_info.get('node_embeddings', [])
            
            if len(node_info) != len(node_embeddings):
                print(f"âŒ ë…¸ë“œ ì •ë³´ì™€ ì„ë² ë”© ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: {len(node_info)} vs {len(node_embeddings)}")
                return
            
            # scene ë…¸ë“œëŠ” ì œì™¸í•˜ê³  ì²˜ë¦¬
            for i, node in enumerate(node_info):
                node_type = node.get('node_type')
                if node_type == 'scene':
                    continue
                
                original_node_id = node.get('node_id')
                node_label = node.get('node_label', 'unknown')
                
                # ì‹¤ì œ node_id ìƒì„±: {video_unique_id}_{scene_id}_{node_type}_{orig_id}
                actual_node_id = f"{video_unique_id}_{scene_id}_{node_type}_{original_node_id}"
                
                # ì„ë² ë”© ë²¡í„° ê°€ì ¸ì˜¤ê¸°
                embedding_vector = node_embeddings[i]
                
                # ì„ë² ë”© ë°ì´í„° ì €ì¥
                embedding_data = {
                    "node_id": actual_node_id,
                    "node_type": node_type,
                    "embedding": embedding_vector
                }
                
                # ì„ë² ë”© ì €ì¥ API í˜¸ì¶œ (ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥)
                response = self.session.post(f"{self.db_api_base_url}/embeddings", json=embedding_data)
                response.raise_for_status()
                
                print(f"  âœ… ì„ë² ë”© ì €ì¥: {node_label} ({node_type}) - {actual_node_id}")
            
            print(f"âœ… ì„ë² ë”© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len([n for n in node_info if n.get('node_type') != 'scene'])}ê°œ")
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    # ==================== ê²€ìƒ‰ ê¸°ëŠ¥ ====================
    
    def vector_search(self, query: str, top_k: int = 5, tau: float = 0.30) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆì˜ë¥¼ tripleë¡œ ë³€í™˜í•˜ê³  ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (BERT ì„ë² ë”© ì‚¬ìš©)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆì˜ ë¬¸ìì—´
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
        
        Returns:
            Dict: ê²€ìƒ‰ ê²°ê³¼ (triples, search_results í¬í•¨)
        """
        try:
            print(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # QueryToTriplesConverter import ë° ì´ˆê¸°í™”
            from reference_query_to_triples_converter import QueryToTriplesConverter
            import os
            
            # 1. ì§ˆë¬¸ì„ triplesë¡œ ë³€í™˜
            converter = QueryToTriplesConverter(
                qa_template_path="templates/qa_to_triple_template.txt",
                api_key=os.getenv("OPENAI_API_KEY"),
                model="gpt-4o-mini"
            )
            
            triples = converter.convert_question(query)
            if not triples:
                print("âŒ ì§ˆë¬¸ì„ tripleë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    "question": query,
                    "triples": [],
                    "search_results": [],
                    "success": False,
                    "error": "ì§ˆë¬¸ì„ tripleë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            print(f"âœ… {len(triples)}ê°œ triple ìƒì„± ì™„ë£Œ")
            
            # 2. DBì—ì„œ triple ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰ (BERTë§Œ ì‚¬ìš©)
            search_results = self._search_triples_in_db(triples, tau, top_k)
            
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            
            return {
                "question": query,
                "triples": triples,
                "search_results": search_results,
                "success": True,
                "tau": tau,
                "top_k": top_k
            }
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {
                "question": query,
                "triples": [],
                "search_results": [],
                "success": False,
                "error": str(e)
            }
    
    def _search_triples_in_db(self, triples: List[List[str]], tau: float, top_k: int) -> List[Dict[str, Any]]:
        """
        2ë‹¨ê³„ pgvector ê¸°ë°˜ triple ê²€ìƒ‰ ìˆ˜í–‰ (BERT ì„ë² ë”© ì‚¬ìš©)
        
        1ë‹¨ê³„: ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë…¸ë“œ ê²€ìƒ‰ (verb > object > subject)
        2ë‹¨ê³„: ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ì°¾ê¸°
        
        Args:
            triples: ê²€ìƒ‰í•  triple ë¦¬ìŠ¤íŠ¸
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            BERT_NAME = "sentence-transformers/all-MiniLM-L6-v2"
            # CUDA ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ CPU ê°•ì œ ì‚¬ìš©
            DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
            
            # SBERT ëª¨ë¸ ì´ˆê¸°í™”
            sbert = SentenceTransformer(BERT_NAME, device=DEVICE).eval()
            
            @torch.no_grad()
            def vec(txt: str) -> torch.Tensor:
                return sbert.encode(txt, normalize_embeddings=True, convert_to_tensor=True).float()
            
            def token_to_sentence(tok: str | None) -> str:
                """
                í† í°ì„ ë¬¸ì¥ í˜•íƒœë¡œ ë³€í™˜
                "person:man" -> "A man which is a kind of person."
                """
                if not tok:
                    return ""
                if ":" in tok:
                    super_type, type_of = tok.split(":", 1)
                    return f"A {type_of} which is a kind of {super_type}."
                else:
                    # ":"ê°€ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                    return tok
            
            def embed_query(tokens: List[str]) -> Tuple[torch.Tensor|None, ...]:
                """BERTë¥¼ ì‚¬ìš©í•œ ì¿¼ë¦¬ ì„ë² ë”©"""
                s_tok, v_tok, o_tok = (tokens + [None, None])[:3]
                
                # Subjectì™€ ObjectëŠ” ë¬¸ì¥ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì„ë² ë”©
                q_s = vec(token_to_sentence(s_tok)) if s_tok and s_tok != "None" else None
                # PredicateëŠ” ê·¸ëŒ€ë¡œ ì„ë² ë”©
                q_v = vec(v_tok) if v_tok and v_tok != "None" else None
                # ObjectëŠ” ë¬¸ì¥ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì„ë² ë”©
                q_o = (
                    vec(token_to_sentence(o_tok))
                    if o_tok and o_tok not in (None, "", "none", "None") else None
                )
                return q_s, q_v, q_o
            
            # 1. triplesë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            print(f"ğŸ” ë³€í™˜í•  triples: {triples}")
            queries_emb = []
            for i, t in enumerate(triples):
                print(f"  Triple {i+1}: {t}")
                try:
                    # BERT ì„ë² ë”© ì‚¬ìš©
                    emb = embed_query(t)
                    print(f"  BERT ì„ë² ë”© ì„±ê³µ: {[type(e).__name__ if e is not None else 'None' for e in emb]}")
                    queries_emb.append(emb)
                except Exception as e:
                    print(f"  âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
                    raise
            total_q = len(queries_emb)
            
            # 2. ì…ë ¥ ê²€ì¦
            for i, triple in enumerate(triples):
                if not any(triple):  # ëª¨ë“  ê°’ì´ None, "", ë˜ëŠ” False
                    raise ValueError(f"Triple {i+1}ì˜ ëª¨ë“  ê°’ì´ nullì…ë‹ˆë‹¤: {triple}")
            
            # 3. ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ì°¾ê¸°
            print(f"ğŸ” ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ê²€ìƒ‰ ì‹œì‘...")
            all_scene_results = self._find_scenes_matching_all_triples(queries_emb, triples, tau, top_k)
            
            return all_scene_results
            
        except Exception as e:
            print(f"âŒ 2ë‹¨ê³„ pgvector Triple ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _find_scenes_matching_all_triples(self, queries_emb: List[Tuple], triples: List[List[str]], tau: float, top_k: int) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ì°¾ê¸°
        
        Args:
            queries_emb: ì„ë² ë”©ëœ triple ë¦¬ìŠ¤íŠ¸
            triples: ì›ë³¸ triple ë¦¬ìŠ¤íŠ¸
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # 1. ê° tripleë³„ë¡œ ìœ ì‚¬í•œ ë…¸ë“œë“¤ ì°¾ê¸°
            all_triple_results = []
            
            for query_idx, (s_emb, v_emb, o_emb) in enumerate(queries_emb):
                print(f"ğŸ” Triple {query_idx + 1} ê²€ìƒ‰ ì¤‘...")
                
                # 1ë‹¨ê³„: ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë…¸ë“œ ê²€ìƒ‰
                similar_nodes = self._find_similar_nodes_by_priority(s_emb, v_emb, o_emb, tau)
                
                print(f"  ğŸ“Š ê²€ìƒ‰ëœ ë…¸ë“œ: Subject {len(similar_nodes['subjects'])}ê°œ, Verb {len(similar_nodes['verbs'])}ê°œ, Object {len(similar_nodes['objects'])}ê°œ")
                
                # 2ë‹¨ê³„: í•´ë‹¹ tripleì˜ ìœ íš¨í•œ ì¡°í•© ì°¾ê¸°
                valid_combinations = self._find_valid_combinations_for_triple(
                    similar_nodes, query_idx, triples[query_idx], s_emb, o_emb
                )
                
                print(f"  âœ… ìœ íš¨í•œ ì¡°í•©: {len(valid_combinations)}ê°œ")
                all_triple_results.append(valid_combinations)
            
            # 2. ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ì°¾ê¸°
            print(f"ğŸ” ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ê²€ìƒ‰...")
            matching_scenes = self._find_scenes_satisfying_all_triples(all_triple_results, triples)
            
            # 3. ê²°ê³¼ ì •ë ¬ ë° ìƒìœ„ kê°œ ì„ íƒ
            matching_scenes.sort(key=lambda x: x['total_avg_similarity'], reverse=True)
            return matching_scenes[:top_k]
            
        except Exception as e:
            print(f"âŒ ëª¨ë“  triple ì¡°ê±´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _find_similar_nodes_by_priority(self, s_emb, v_emb, o_emb, tau: float) -> Dict[str, List]:
        """
        ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ìœ ì‚¬í•œ ë…¸ë“œë“¤ ì°¾ê¸° (ìµœì í™”ëœ ë²„ì „)
        
        1. predicateê°€ Noneì´ ì•„ë‹Œ ê²½ìš°:
           - Event ë…¸ë“œì™€ Spatial ë…¸ë“œì˜ ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒì„ íƒìƒ‰
           - íƒìƒ‰ëœ predicateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ê²°ëœ subjectì™€ object ë…¸ë“œë¥¼ DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ ê²€ìƒ‰
           - Noneì¸ ê²ƒì€ íƒìƒ‰ ëŒ€ìƒì—ì„œ ë°°ì œí•˜ê³  ì•„ë‹Œ ë¶€ë¶„ì„ ì´ìš©í•´ì„œ íƒìƒ‰
        
        2. predicateê°€ Noneì¸ ê²½ìš°:
           - subjectì™€ objectë¥¼ ì´ìš©í•´ì„œ íƒìƒ‰ ì‹¤ì‹œ
           - Noneì¸ ê²ƒì€ íƒìƒ‰ ëŒ€ìƒì—ì„œ ë°°ì œí•˜ê³  ì•„ë‹Œ ë¶€ë¶„ì„ ì´ìš©í•´ì„œ íƒìƒ‰
        
        3. subject, predicate, object ëª¨ë‘ Noneì¸ ê²½ìš°:
           - íƒìƒ‰ ì‹¤ì‹œí•˜ì§€ ì•ŠìŒ
        """
        similar_nodes = {
            'subjects': [],
            'verbs': [],
            'objects': []
        }
        
        # 1. predicateê°€ Noneì´ ì•„ë‹Œ ê²½ìš°
        if v_emb is not None:
            print(f"  ğŸ” Predicate ê¸°ì¤€ ê²€ìƒ‰ ì‹œì‘")
            
            # Event ë…¸ë“œì™€ Spatial ë…¸ë“œ ê²€ìƒ‰ (ì „ì—­ ê²€ìƒ‰)
            event_nodes = self._find_similar_nodes_with_pgvector(v_emb, 'event', tau)
            try:
                spatial_nodes = self._find_similar_nodes_with_pgvector(v_emb, 'spatial', tau)
            except Exception as e:
                print(f"  âš ï¸ Spatial ë…¸ë“œ ê²€ìƒ‰ ì‹¤íŒ¨, Event ë…¸ë“œë§Œ ì‚¬ìš©: {e}")
                spatial_nodes = []
            
            print(f"  ğŸ“Š Event ë…¸ë“œ: {len(event_nodes)}ê°œ, Spatial ë…¸ë“œ: {len(spatial_nodes)}ê°œ")
            
            # ê° predicate ë…¸ë“œì— ëŒ€í•´ ì—°ê²°ëœ ë…¸ë“œë“¤ì„ DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ ê²€ìƒ‰
            for predicate_node in event_nodes + spatial_nodes:
                scene_id = predicate_node.get('scene_id')
                if not scene_id:
                    continue
                
                # ì—°ê²°ëœ ë…¸ë“œë“¤ì„ DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ ê²€ìƒ‰
                connected_nodes = self._find_connected_nodes_with_similarity(
                    scene_id, predicate_node, s_emb, o_emb, tau
                )
                
                # ê²°ê³¼ ì¶”ê°€
                similar_nodes['subjects'].extend(connected_nodes['subjects'])
                similar_nodes['objects'].extend(connected_nodes['objects'])
                similar_nodes['verbs'].append(predicate_node)
        
        # 2. predicateê°€ Noneì¸ ê²½ìš°
        elif s_emb is not None or o_emb is not None:
            print(f"  ğŸ” Subject/Object ê¸°ì¤€ ê²€ìƒ‰ ì‹œì‘")
            
            # Subjectê°€ Noneì´ ì•„ë‹Œ ê²½ìš°: ì „ì—­ ê²€ìƒ‰
            if s_emb is not None:
                similar_nodes['subjects'] = self._find_similar_nodes_with_pgvector(s_emb, 'object', tau)
                print(f"  ğŸ“Š Subject ë…¸ë“œ: {len(similar_nodes['subjects'])}ê°œ")
            
            # Objectê°€ Noneì´ ì•„ë‹Œ ê²½ìš°: ì „ì—­ ê²€ìƒ‰
            if o_emb is not None:
                similar_nodes['objects'] = self._find_similar_nodes_with_pgvector(o_emb, 'object', tau)
                print(f"  ğŸ“Š Object ë…¸ë“œ: {len(similar_nodes['objects'])}ê°œ")
            
            # Subjectì™€ Objectê°€ ê°™ì€ ì¥ë©´ì— ìˆëŠ”ì§€ í™•ì¸
            if s_emb is not None and o_emb is not None:
                valid_subjects = []
                valid_objects = []
                
                for subject in similar_nodes['subjects']:
                    for obj in similar_nodes['objects']:
                        if subject.get('scene_id') == obj.get('scene_id'):
                            valid_subjects.append(subject)
                            valid_objects.append(obj)
                
                similar_nodes['subjects'] = valid_subjects
                similar_nodes['objects'] = valid_objects
                print(f"  âœ… ê°™ì€ ì¥ë©´ì˜ Subject-Object ìŒ: {len(valid_subjects)}ê°œ")
        
        # 3. subject, predicate, object ëª¨ë‘ Noneì¸ ê²½ìš°: ê²€ìƒ‰í•˜ì§€ ì•ŠìŒ
        else:
            print("  âš ï¸ ëª¨ë“  ìš”ì†Œê°€ Noneì´ë¯€ë¡œ ê²€ìƒ‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        return similar_nodes
    
    def _find_connected_nodes_with_similarity(self, scene_id: int, predicate_node: Dict[str, Any], 
                                            s_emb: torch.Tensor = None, o_emb: torch.Tensor = None, 
                                            tau: float = 0.1) -> Dict[str, List]:
        """
        ì¥ë©´ ë‚´ ì—°ê²°ëœ ë…¸ë“œë“¤ì„ DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ ê²€ìƒ‰
        
        Args:
            scene_id: ì¥ë©´ ID
            predicate_node: predicate ë…¸ë“œ ì •ë³´
            s_emb: subject ì„ë² ë”©
            o_emb: object ì„ë² ë”©
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            ì—°ê²°ëœ ë…¸ë“œë“¤ì˜ ë”•ì…”ë„ˆë¦¬
        """
        connected_nodes = {
            'subjects': [],
            'objects': []
        }
        
        try:
            # Event ë…¸ë“œì¸ ê²½ìš°
            if 'event_id' in predicate_node:
                subject_id = predicate_node.get('subject_id')
                object_id = predicate_node.get('object_id')
                
                print(f"  ğŸ” Event {predicate_node.get('event_id')} ë§¤ì¹­ ì‹œë„:")
                print(f"    - Subject ID: {subject_id}")
                print(f"    - Object ID: {object_id}")
                
                # Subject ë…¸ë“œ ìœ ì‚¬ë„ ê²€ìƒ‰ (DBì—ì„œ ê³„ì‚°)
                if s_emb is not None and subject_id:
                    # ì¥ë©´ ë‚´ì—ì„œ ìœ ì‚¬í•œ Subject ê²€ìƒ‰ (specific_node_id ì—†ì´)
                    # Subject ê²€ìƒ‰ì€ ë” ê´€ëŒ€í•œ ì„ê³„ê°’ ì‚¬ìš© (tauì˜ 50%)
                    subject_tau = max(0.0, tau * 0.5)
                    subject_results = self._search_similarity_in_db(
                        s_emb, 'object', subject_tau, 
                        scene_id=scene_id
                    )
                    # ê²€ìƒ‰ëœ Subject ì¤‘ì—ì„œ Eventì˜ subject_idì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
                    matching_subjects = [s for s in subject_results if s['object_id'] == subject_id]
                    connected_nodes['subjects'].extend(matching_subjects)
                    print(f"  ğŸ“Š Subject ê²€ìƒ‰ ê²°ê³¼: {len(subject_results)}ê°œ (ì¥ë©´ ë‚´)")
                    print(f"    - ë§¤ì¹­ëœ Subject: {len(matching_subjects)}ê°œ")
                    if matching_subjects:
                        print(f"    - ì°¾ì€ Subject: {[s['object_id'] for s in matching_subjects]}")
                    else:
                        print(f"    - Subject ë§¤ì¹­ ì‹¤íŒ¨: {subject_id}")
                
                # Object ë…¸ë“œ ìœ ì‚¬ë„ ê²€ìƒ‰ (DBì—ì„œ ê³„ì‚°)
                if object_id:
                    # o_embê°€ Noneì´ì–´ë„ object ê²€ìƒ‰ ìˆ˜í–‰ (ê¸°ë³¸ ì„ë² ë”© ì‚¬ìš©)
                    if o_emb is not None:
                        # ì¥ë©´ ë‚´ì—ì„œ ìœ ì‚¬í•œ Object ê²€ìƒ‰ (specific_node_id ì—†ì´)
                        # Object ê²€ìƒ‰ì€ ë” ê´€ëŒ€í•œ ì„ê³„ê°’ ì‚¬ìš© (tauì˜ 50%)
                        object_tau = max(0.0, tau * 0.5)
                        object_results = self._search_similarity_in_db(
                            o_emb, 'object', object_tau,
                            scene_id=scene_id
                        )
                        # ê²€ìƒ‰ëœ Object ì¤‘ì—ì„œ Eventì˜ object_idì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
                        matching_objects = [o for o in object_results if o['object_id'] == object_id]
                        connected_nodes['objects'].extend(matching_objects)
                        print(f"  ğŸ“Š Object ê²€ìƒ‰ ê²°ê³¼: {len(object_results)}ê°œ (ì¥ë©´ ë‚´)")
                        print(f"    - ë§¤ì¹­ëœ Object: {len(matching_objects)}ê°œ")
                        if matching_objects:
                            print(f"    - ì°¾ì€ Object: {[o['object_id'] for o in matching_objects]}")
                        else:
                            print(f"    - Object ë§¤ì¹­ ì‹¤íŒ¨: {object_id}")
                    else:
                        # o_embê°€ Noneì¸ ê²½ìš°, object_idë§Œìœ¼ë¡œ ê²€ìƒ‰ (ìœ ì‚¬ë„ ê³„ì‚° ì—†ì´)
                        # ì¥ë©´ ë‚´ì—ì„œ í•´ë‹¹ object_idë¥¼ ê°€ì§„ ê°ì²´ë¥¼ ì°¾ê¸°
                        object_results = self._search_similarity_in_db(
                            None, 'object', 0.0,  # ìœ ì‚¬ë„ ê³„ì‚° ì—†ì´
                            scene_id=scene_id, specific_node_id=object_id
                        )
                        if object_results:
                            connected_nodes['objects'].extend(object_results)
                            print(f"  ğŸ“Š Object ê²€ìƒ‰ ê²°ê³¼: {len(object_results)}ê°œ (ì¥ë©´ ë‚´)")
                            print(f"    - ì°¾ì€ Object: {[o['object_id'] for o in object_results]}")
                        else:
                            print(f"    - Object ë§¤ì¹­ ì‹¤íŒ¨: {object_id}")
            
            # Spatial ë…¸ë“œì¸ ê²½ìš°
            elif 'spatial_id' in predicate_node:
                subject_id = predicate_node.get('subject_id')
                object_id = predicate_node.get('object_id')
                
                print(f"  ğŸ” Spatial {predicate_node.get('spatial_id')} ë§¤ì¹­ ì‹œë„:")
                print(f"    - Subject ID: {subject_id}")
                print(f"    - Object ID: {object_id}")
                
                # Subject ë…¸ë“œ ìœ ì‚¬ë„ ê²€ìƒ‰ (DBì—ì„œ ê³„ì‚°)
                if s_emb is not None and subject_id:
                    # ì¥ë©´ ë‚´ì—ì„œ ìœ ì‚¬í•œ Subject ê²€ìƒ‰ (specific_node_id ì—†ì´)
                    subject_tau = max(0.0, tau * 0.5)  # Subject ê²€ìƒ‰ì„ ìœ„í•œ ë” ê´€ëŒ€í•œ ì„ê³„ê°’
                    subject_results = self._search_similarity_in_db(
                        s_emb, 'object', subject_tau,
                        scene_id=scene_id
                    )
                    # ê²€ìƒ‰ëœ Subject ì¤‘ì—ì„œ Spatialì˜ subject_idì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
                    matching_subjects = [s for s in subject_results if s['object_id'] == subject_id]
                    connected_nodes['subjects'].extend(matching_subjects)
                    print(f"  ğŸ“Š Subject ê²€ìƒ‰ ê²°ê³¼: {len(subject_results)}ê°œ (ì¥ë©´ ë‚´)")
                    print(f"    - ë§¤ì¹­ëœ Subject: {len(matching_subjects)}ê°œ")
                    if matching_subjects:
                        print(f"    - ì°¾ì€ Subject: {[s['object_id'] for s in matching_subjects]}")
                    else:
                        print(f"    - Subject ë§¤ì¹­ ì‹¤íŒ¨: {subject_id}")
                
                # Object ë…¸ë“œ ìœ ì‚¬ë„ ê²€ìƒ‰ (DBì—ì„œ ê³„ì‚°)
                if object_id:
                    # o_embê°€ Noneì´ì–´ë„ object ê²€ìƒ‰ ìˆ˜í–‰ (ê¸°ë³¸ ì„ë² ë”© ì‚¬ìš©)
                    if o_emb is not None:
                        # ì¥ë©´ ë‚´ì—ì„œ ìœ ì‚¬í•œ Object ê²€ìƒ‰ (specific_node_id ì—†ì´)
                        object_tau = max(0.0, tau * 0.5)  # Object ê²€ìƒ‰ì„ ìœ„í•œ ë” ê´€ëŒ€í•œ ì„ê³„ê°’
                        object_results = self._search_similarity_in_db(
                            o_emb, 'object', object_tau,
                            scene_id=scene_id
                        )
                        # ê²€ìƒ‰ëœ Object ì¤‘ì—ì„œ Spatialì˜ object_idì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
                        matching_objects = [o for o in object_results if o['object_id'] == object_id]
                        connected_nodes['objects'].extend(matching_objects)
                        print(f"  ğŸ“Š Object ê²€ìƒ‰ ê²°ê³¼: {len(object_results)}ê°œ (ì¥ë©´ ë‚´)")
                        print(f"    - ë§¤ì¹­ëœ Object: {len(matching_objects)}ê°œ")
                        if matching_objects:
                            print(f"    - ì°¾ì€ Object: {[o['object_id'] for o in matching_objects]}")
                        else:
                            print(f"    - Object ë§¤ì¹­ ì‹¤íŒ¨: {object_id}")
                    else:
                        # o_embê°€ Noneì¸ ê²½ìš°, object_idë§Œìœ¼ë¡œ ê²€ìƒ‰ (ìœ ì‚¬ë„ ê³„ì‚° ì—†ì´)
                        # ì¥ë©´ ë‚´ì—ì„œ í•´ë‹¹ object_idë¥¼ ê°€ì§„ ê°ì²´ë¥¼ ì°¾ê¸°
                        object_results = self._search_similarity_in_db(
                            None, 'object', 0.0,  # ìœ ì‚¬ë„ ê³„ì‚° ì—†ì´
                            scene_id=scene_id, specific_node_id=object_id
                        )
                        if object_results:
                            connected_nodes['objects'].extend(object_results)
                            print(f"  ğŸ“Š Object ê²€ìƒ‰ ê²°ê³¼: {len(object_results)}ê°œ (ì¥ë©´ ë‚´)")
                            print(f"    - ì°¾ì€ Object: {[o['object_id'] for o in object_results]}")
                        else:
                            print(f"    - Object ë§¤ì¹­ ì‹¤íŒ¨: {object_id}")
            
            print(f"  ğŸ“Š ì—°ê²°ëœ ë…¸ë“œ: Subject {len(connected_nodes['subjects'])}ê°œ, Object {len(connected_nodes['objects'])}ê°œ")
            
        except Exception as e:
            print(f"âŒ ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return connected_nodes

    def _search_similarity_in_db(self, query_emb: torch.Tensor, node_type: str, tau: float, 
                               scene_id: int = None, specific_node_id: str = None) -> List[Dict[str, Any]]:
        """
        DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ ê²€ìƒ‰ (ì„œë²„ì—ì„œ pgvector ì‚¬ìš©)
        
        Args:
            query_emb: ì¿¼ë¦¬ ì„ë² ë”©
            node_type: ë…¸ë“œ íƒ€ì…
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
            scene_id: ì¥ë©´ ID (ì„ íƒì‚¬í•­)
            specific_node_id: íŠ¹ì • ë…¸ë“œ ID (ì„ íƒì‚¬í•­)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if query_emb is None:
            # query_embê°€ Noneì¸ ê²½ìš°, specific_node_idë§Œìœ¼ë¡œ ê²€ìƒ‰
            if specific_node_id is None:
                return []
            # specific_node_idê°€ ìˆëŠ” ê²½ìš°, í•´ë‹¹ ë…¸ë“œë¥¼ ì§ì ‘ ì¡°íšŒ
            # ì´ ê²½ìš° ìœ ì‚¬ë„ ê³„ì‚° ì—†ì´ ì •í™•í•œ ë§¤ì¹­ë§Œ ìˆ˜í–‰
            request_data = {
                "node_type": node_type,
                "specific_node_id": specific_node_id
            }
            if scene_id is not None:
                request_data["scene_id"] = scene_id
            
            try:
                response = self.session.post(f"{self.db_api_base_url}/search/vector", json=request_data)
                response.raise_for_status()
                result = response.json()
                # ì„œë²„ê°€ ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš°ì™€ {'results': [...]} í˜•íƒœë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                if isinstance(result, list):
                    return result
                else:
                    return result.get('results', [])
            except Exception as e:
                print(f"âŒ specific_node_id ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                return []
        
        # ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        query_vector = query_emb.tolist()
        
        # API ìš”ì²­ ë°ì´í„° êµ¬ì„±
        request_data = {
            "query_embedding": query_vector,
            "node_type": node_type,
            "tau": tau,
            "top_k": 10
        }
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ê°€
        if scene_id is not None:
            request_data["scene_id"] = scene_id
        if specific_node_id is not None:
            request_data["specific_node_id"] = specific_node_id
        
        try:
            # API í˜¸ì¶œ (ì„œë²„ì—ì„œ pgvectorë¡œ ìœ ì‚¬ë„ ê³„ì‚°)
            response = self.session.post(
                f"{self.db_api_base_url}/search/vector",
                json=request_data,
                timeout=30
            )
            
            if response.status_code == 200:
                results = response.json()
                return results
            else:
                print(f"âŒ {node_type} ë…¸ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ {node_type} ë…¸ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _find_node_by_id(self, node_id: str, node_type: str, scene_id: int) -> Dict[str, Any]:
        """
        íŠ¹ì • IDë¡œ ë…¸ë“œ ê²€ìƒ‰
        
        Args:
            node_id: ë…¸ë“œ ID
            node_type: ë…¸ë“œ íƒ€ì… ('object', 'event', 'spatial')
            scene_id: ì¥ë©´ ID
            
        Returns:
            ë…¸ë“œ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        try:
            print(f"ğŸ” ë…¸ë“œ ê²€ìƒ‰: node_id={node_id}, node_type={node_type}, scene_id={scene_id}")
            
            # APIë¥¼ í†µí•´ íŠ¹ì • ë…¸ë“œ ê²€ìƒ‰
            if node_type == 'object':
                response = self.session.get(f"{self.db_api_base_url}/objects")
            elif node_type == 'event':
                response = self.session.get(f"{self.db_api_base_url}/events")
            elif node_type == 'spatial':
                response = self.session.get(f"{self.db_api_base_url}/spatial")
            else:
                return None
            
            if response.status_code == 200:
                nodes = response.json()
                print(f"ğŸ“Š {node_type} ë…¸ë“œ ê°œìˆ˜: {len(nodes)}")
                
                for node in nodes:
                    node_key = 'object_id' if node_type == 'object' else 'event_id' if node_type == 'event' else 'spatial_id'
                    if node.get(node_key) == node_id:
                        if node.get('scene_id') == scene_id:
                            print(f"âœ… ë…¸ë“œ ì°¾ìŒ: {node_id}")
                            return node
                        else:
                            print(f"âš ï¸ ë…¸ë“œëŠ” ìˆì§€ë§Œ ë‹¤ë¥¸ ì¥ë©´: {node_id} (scene_id: {node.get('scene_id')})")
                
                print(f"âŒ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {node_id}")
                return None
            else:
                print(f"âŒ ë…¸ë“œ ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ ë…¸ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    
    def _find_valid_combinations_for_triple(self, similar_nodes: Dict[str, List], query_idx: int, triple: List[str], s_emb: torch.Tensor = None, o_emb: torch.Tensor = None) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • tripleì— ëŒ€í•œ ìœ íš¨í•œ ì¡°í•© ì°¾ê¸°
        ì´ë¯¸ predicate ê¸°ì¤€ìœ¼ë¡œ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë‹¨ìˆœíˆ ê²°ê³¼ë¥¼ ë°˜í™˜
        """
        valid_combinations = []
        
        # Predicateê°€ ìˆëŠ” ê²½ìš°: ì´ë¯¸ ë§¤ì¹­ëœ ê²°ê³¼ë“¤ì„ ì¡°í•©
        if similar_nodes['verbs']:
            # Event ë…¸ë“œë“¤ ì²˜ë¦¬
            for verb_node in similar_nodes['verbs']:
                if 'event_id' in verb_node:
                    # í•´ë‹¹ eventì™€ ë§¤ì¹­ë˜ëŠ” subject, object ì°¾ê¸°
                    subject_match = None
                    object_match = None
                    
                    print(f"    ğŸ” Event {verb_node.get('event_id')} ë§¤ì¹­ ì‹œë„:")
                    print(f"      - Subject ID: {verb_node.get('subject_id')}")
                    print(f"      - Object ID: {verb_node.get('object_id')}")
                    print(f"      - Available subjects: {[s['object_id'] for s in similar_nodes['subjects']]}")
                    print(f"      - Available objects: {[o['object_id'] for o in similar_nodes['objects']]}")
                    
                    for subject in similar_nodes['subjects']:
                        if subject['object_id'] == verb_node.get('subject_id'):
                            subject_match = subject
                            print(f"      âœ… Subject ë§¤ì¹­ ì„±ê³µ: {subject['object_id']} (ìœ ì‚¬ë„: {subject['similarity']:.3f})")
                            break
                    
                    # Subject ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
                    if not subject_match:
                        print(f"      âŒ Subject ë§¤ì¹­ ì‹¤íŒ¨: {verb_node.get('subject_id')}")
                        print(f"        - Available subjects: {[s['object_id'] for s in similar_nodes['subjects']]}")
                    
                    for obj in similar_nodes['objects']:
                        if obj['object_id'] == verb_node.get('object_id'):
                            object_match = obj
                            print(f"      âœ… Object ë§¤ì¹­ ì„±ê³µ: {obj['object_id']} (ìœ ì‚¬ë„: {obj['similarity']:.3f})")
                            break
                    
                    # Subjectê°€ ë§¤ì¹­ë˜ì–´ì•¼ë§Œ ê²°ê³¼ ìƒì„± (Subject ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš°ëŠ” ì œì™¸)
                    if subject_match and (object_match or not verb_node.get('object_id')):
                        # ìœ ì‚¬ë„ ê³„ì‚°
                        subject_sim = subject_match['similarity'] if subject_match else 0.0
                        verb_sim = verb_node['similarity']
                        object_sim = object_match['similarity'] if object_match else 0.0
                        
                        # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                        if subject_match and object_match and verb_node.get('object_id'):
                            avg_similarity = (subject_sim + verb_sim + object_sim) / 3
                        elif subject_match:
                            avg_similarity = (subject_sim + verb_sim) / 2
                        else:
                            # Subjectê°€ Noneì¸ ê²½ìš° Predicateë§Œìœ¼ë¡œ ê³„ì‚°
                            avg_similarity = verb_sim
                        
                        valid_combinations.append({
                            "query_idx": query_idx,
                            "subject_id": verb_node.get('subject_id'),
                            "subject_similarity": subject_sim,
                            "subject_info": subject_match,
                            "event_id": verb_node['event_id'],
                            "event_similarity": verb_sim,
                            "object_id": verb_node.get('object_id'),
                            "object_similarity": object_sim if verb_node.get('object_id') and object_match else None,
                            "object_info": object_match,
                            "verb": verb_node['verb'],
                            "avg_similarity": avg_similarity,
                            "scene_id": verb_node['scene_id'],
                            "scene_number": verb_node['scene_number'],
                            "drama_name": verb_node.get('drama_name', 'Unknown'),
                            "episode_number": verb_node.get('episode_number', 'Unknown'),
                            "video_unique_id": verb_node.get('video_unique_id', 0),
                            "type": "event_triple"
                        })
            
            # Spatial ë…¸ë“œë“¤ ì²˜ë¦¬
            for verb_node in similar_nodes['verbs']:
                if 'spatial_id' in verb_node:
                    # í•´ë‹¹ spatialê³¼ ë§¤ì¹­ë˜ëŠ” subject, object ì°¾ê¸°
                    subject_match = None
                    object_match = None
                    
                    for subject in similar_nodes['subjects']:
                        if subject['object_id'] == verb_node.get('subject_id'):
                            subject_match = subject
                            break
                    
                    for obj in similar_nodes['objects']:
                        if obj['object_id'] == verb_node.get('object_id'):
                            object_match = obj
                            break
                    
                    # Subjectê°€ ë§¤ì¹­ë˜ì–´ì•¼ë§Œ ê²°ê³¼ ìƒì„± (Subject ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš°ëŠ” ì œì™¸)
                    if subject_match and object_match:
                        # ìœ ì‚¬ë„ ê³„ì‚°
                        subject_sim = subject_match['similarity'] if subject_match else 0.0
                        predicate_sim = verb_node['similarity']
                        object_sim = object_match['similarity'] if object_match else 0.0
                        
                        # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                        if subject_match and object_match:
                            avg_similarity = (subject_sim + predicate_sim + object_sim) / 3
                        else:
                            # Subjectê°€ Noneì¸ ê²½ìš° Predicateë§Œìœ¼ë¡œ ê³„ì‚°
                            avg_similarity = predicate_sim
                        
                        valid_combinations.append({
                            "query_idx": query_idx,
                            "subject_id": verb_node.get('subject_id'),
                            "subject_similarity": subject_sim,
                            "subject_info": subject_match,
                            "spatial_id": verb_node['spatial_id'],
                            "predicate_similarity": predicate_sim,
                            "object_id": verb_node.get('object_id'),
                            "object_similarity": object_sim,
                            "object_info": object_match,
                            "predicate": verb_node['predicate'],
                            "avg_similarity": avg_similarity,
                            "scene_id": verb_node['scene_id'],
                            "scene_number": verb_node['scene_number'],
                            "drama_name": verb_node.get('drama_name', 'Unknown'),
                            "episode_number": verb_node.get('episode_number', 'Unknown'),
                            "video_unique_id": verb_node.get('video_unique_id', 0),
                            "type": "spatial_triple"
                        })
        
        # Predicateê°€ Noneì¸ ê²½ìš°: subjectì™€ objectë§Œìœ¼ë¡œ ë§¤ì¹­
        else:
            for subject in similar_nodes['subjects']:
                for obj in similar_nodes['objects']:
                    # ê°™ì€ ì¥ë©´ì— ìˆëŠ”ì§€ í™•ì¸
                    if subject.get('scene_id') == obj.get('scene_id'):
                        # ìœ ì‚¬ë„ ê³„ì‚°
                        subject_sim = subject['similarity']
                        object_sim = obj['similarity']
                        avg_similarity = (subject_sim + object_sim) / 2
                        
                        valid_combinations.append({
                            "query_idx": query_idx,
                            "subject_id": subject['object_id'],
                            "subject_similarity": subject_sim,
                            "object_id": obj['object_id'],
                            "object_similarity": object_sim,
                            "avg_similarity": avg_similarity,
                            "scene_id": subject['scene_id'],
                            "scene_number": subject['scene_number'],
                            "drama_name": subject.get('drama_name', 'Unknown'),
                            "episode_number": subject.get('episode_number', 'Unknown'),
                            "video_unique_id": subject.get('video_unique_id', 0),
                            "type": "subject_object_only"
                        })
        
        return valid_combinations
    
    def _find_scenes_satisfying_all_triples(self, all_triple_results: List[List[Dict]], triples: List[List[str]]) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” scene ì°¾ê¸°
        """
        if not all_triple_results:
            return []
        
        # ì²« ë²ˆì§¸ tripleì˜ ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘
        base_results = all_triple_results[0]
        matching_scenes = []
        
        for base_result in base_results:
            scene_id = base_result['scene_id']
            video_id = base_result.get('video_unique_id')
            
            # ì´ sceneì´ ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
            satisfied_triples = [base_result]
            
            for triple_idx in range(1, len(all_triple_results)):
                triple_results = all_triple_results[triple_idx]
                
                # ê°™ì€ sceneì—ì„œ ì´ tripleì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
                matching_result = None
                for result in triple_results:
                    if result['scene_id'] == scene_id:
                        matching_result = result
                        break
                
                if matching_result:
                    satisfied_triples.append(matching_result)
                else:
                    # ì´ sceneì€ ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŒ
                    break
            
            # ëª¨ë“  triple ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê²½ìš°
            if len(satisfied_triples) == len(triples):
                # ì „ì²´ ìœ ì‚¬ë„ ê³„ì‚°
                total_avg_similarity = sum(t['avg_similarity'] for t in satisfied_triples) / len(satisfied_triples)
                
                matching_scenes.append({
                    "scene_id": scene_id,
                    "scene_number": base_result['scene_number'],
                    "drama_name": base_result['drama_name'],
                    "episode_number": base_result['episode_number'],
                    "video_unique_id": base_result['video_unique_id'],
                    "total_avg_similarity": total_avg_similarity,
                    "satisfied_triples": satisfied_triples,
                    "triple_count": len(satisfied_triples),
                    "total_triples": len(triples)
                })
        
        return matching_scenes
    
    def _find_similar_nodes_with_pgvector(self, query_emb: torch.Tensor, node_type: str, tau: float, top_k: int = 100) -> List[Dict[str, Any]]:
        """pgvectorë¡œ ìœ ì‚¬í•œ ë…¸ë“œë“¤ ì°¾ê¸°"""
        if query_emb is None:
            return []
        
        # ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        query_vector = query_emb.tolist()
        
        # API ìš”ì²­ ë°ì´í„° êµ¬ì„±
        request_data = {
            "query_embedding": query_vector,
            "node_type": node_type,
            "tau": tau,
            "top_k": 100
        }
        
        try:
            # API í˜¸ì¶œ
            response = self.session.post(
                f"{self.db_api_base_url}/search/vector",
                json=request_data,
                timeout=30
            )
            
            if response.status_code == 200:
                results = response.json()
                return results
            else:
                print(f"âŒ {node_type} ë…¸ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ {node_type} ë…¸ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _find_related_triples_with_pgvector(self, subjects: List[Dict], verbs: List[Dict], 
                                          objects: List[Dict], query_idx: int) -> List[Dict[str, Any]]:
        """ì‹¤ì œ ê´€ê³„ë¥¼ ê°€ì§€ëŠ” Triple ì¡°í•© ì°¾ê¸°"""
        if not subjects or not verbs:
            return []
        
        # ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (API ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        subject_ids = [s['object_id'] for s in subjects]
        verb_ids = [v['event_id'] for v in verbs]
        object_ids = [o['object_id'] for o in objects] if objects else []
        
        # ìœ ì‚¬ë„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        subject_sim_map = {s['object_id']: s['similarity'] for s in subjects}
        verb_sim_map = {v['event_id']: v['similarity'] for v in verbs}
        object_sim_map = {o['object_id']: o['similarity'] for o in objects}
        
        # ê´€ê³„ í™•ì¸ì„ ìœ„í•œ API ìš”ì²­
        try:
            valid_triples = []
            
            # ë¹„ë””ì˜¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê°™ì€ ë¹„ë””ì˜¤ ë‚´ì—ì„œ ê´€ê³„ ì°¾ê¸°
            video_groups = {}
            
            # Subjectë“¤ì„ ë¹„ë””ì˜¤ë³„ë¡œ ê·¸ë£¹í™”
            for subject in subjects:
                video_id = subject.get('video_id')
                if video_id not in video_groups:
                    video_groups[video_id] = {'subjects': [], 'verbs': [], 'objects': []}
                video_groups[video_id]['subjects'].append(subject)
            
            # Verbë“¤ì„ ë¹„ë””ì˜¤ë³„ë¡œ ê·¸ë£¹í™”
            for verb in verbs:
                video_id = verb.get('video_id')
                if video_id not in video_groups:
                    video_groups[video_id] = {'subjects': [], 'verbs': [], 'objects': []}
                video_groups[video_id]['verbs'].append(verb)
            
            # Objectë“¤ì„ ë¹„ë””ì˜¤ë³„ë¡œ ê·¸ë£¹í™”
            for obj in objects:
                video_id = obj.get('video_id')
                if video_id not in video_groups:
                    video_groups[video_id] = {'subjects': [], 'verbs': [], 'objects': []}
                video_groups[video_id]['objects'].append(obj)
            
            # ê° ë¹„ë””ì˜¤ë³„ë¡œ ê´€ê³„ í™•ì¸
            for video_id, groups in video_groups.items():
                if not groups['subjects'] or not groups['verbs']:
                    continue
                
                # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¥ë©´ì—ì„œ ì´ë²¤íŠ¸ í™•ì¸
                scenes = self.get_scenes(video_id)
                
                for scene in scenes:
                    scene_id = scene['id']
                    events = self.get_scene_events(scene_id)
                    
                    for event in events:
                        event_id = event['event_id']
                        subject_id = event['subject_id']
                        object_id = event.get('object_id')
                        verb = event['verb']
                        
                        # Subjectì™€ Verbê°€ ëª¨ë‘ ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ”ì§€ í™•ì¸
                        subject_match = None
                        verb_match = None
                        object_match = None
                        
                        # Subject ë§¤ì¹­
                        for s in groups['subjects']:
                            if s['object_id'] == subject_id:
                                subject_match = s
                                break
                        
                        # Verb ë§¤ì¹­
                        for v in groups['verbs']:
                            if v['event_id'] == event_id:
                                verb_match = v
                                break
                        
                        # Object ë§¤ì¹­ (ìˆëŠ” ê²½ìš°)
                        if object_id and groups['objects']:
                            for o in groups['objects']:
                                if o['object_id'] == object_id:
                                    object_match = o
                                    break
                        elif not object_id and not groups['objects']:
                            # Objectê°€ ì—†ê³  ê²€ìƒ‰ ê²°ê³¼ì—ë„ ì—†ëŠ” ê²½ìš° (ì •ìƒ)
                            object_match = True
                        
                        # ëª¨ë“  ìš”ì†Œê°€ ë§¤ì¹­ë˜ë©´ ìœ íš¨í•œ Triple
                        if subject_match and verb_match and (object_match or object_match is True):
                            subject_sim = subject_match['similarity']
                            verb_sim = verb_match['similarity']
                            object_sim = object_match['similarity'] if object_match and object_match is not True else 0.0
                            
                            # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                            if object_id and object_match and object_match is not True:
                                avg_similarity = (subject_sim + verb_sim + object_sim) / 3
                            else:
                                avg_similarity = (subject_sim + verb_sim) / 2
                            
                            valid_triples.append({
                                "query_idx": query_idx,
                                "subject_id": subject_id,
                                "subject_similarity": subject_sim,
                                "event_id": event_id,
                                "event_similarity": verb_sim,
                                "object_id": object_id,
                                "object_similarity": object_sim if object_id and object_match and object_match is not True else None,
                                "verb": verb,
                                "avg_similarity": avg_similarity,
                                "scene_id": scene_id,
                                "scene_number": scene['scene_number'],
                                "drama_name": subject_match.get('drama_name', 'Unknown'),
                                "episode_number": subject_match.get('episode_number', 'Unknown'),
                                "video_unique_id": subject_match.get('video_unique_id', 0)
                            })
            
            return valid_triples
            
        except Exception as e:
            print(f"âŒ ê´€ê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def _find_similar_nodes_in_scene(self, query_emb: torch.Tensor, node_type: str, scene_id: int, tau: float) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë©´ì—ì„œ ìœ ì‚¬í•œ ë…¸ë“œë“¤ ì°¾ê¸°"""
        if query_emb is None:
            return []
        
        # ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        query_vector = query_emb.tolist()
        
        # API ìš”ì²­ ë°ì´í„° êµ¬ì„±
        request_data = {
            "query_embedding": query_vector,
            "node_type": node_type,
            "tau": tau,
            "top_k": 50,
            "scene_id": scene_id  # íŠ¹ì • ì¥ë©´ìœ¼ë¡œ ì œí•œ
        }
        
        try:
            # API í˜¸ì¶œ
            response = self.session.post(
                f"{self.db_api_base_url}/search/vector",
                json=request_data,
                timeout=30
            )
            
            if response.status_code == 200:
                results = response.json()
                return results
            else:
                print(f"âŒ ì¥ë©´ ë‚´ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ ì¥ë©´ ë‚´ ë²¡í„° ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def print_search_results(self, search_results: List[Dict[str, Any]], triples: List[List[str]]) -> None:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Args:
            search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            triples: ê²€ìƒ‰ì— ì‚¬ìš©ëœ triple ë¦¬ìŠ¤íŠ¸
        """
        if not search_results:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n=== ê²€ìƒ‰ ê²°ê³¼ ===")
        for i, result in enumerate(search_results, 1):
            print(f"\n{i}. ì¥ë©´: {result['drama_name']} {result['episode_number']} - {result['scene_number']}")
            print(f"   ì „ì²´ í‰ê·  ìœ ì‚¬ë„: {result['total_avg_similarity']:.3f}")
            print(f"   ì¥ë©´ ID: {result['scene_id']}")
            print(f"   ë§¤ì¹­ëœ Triple: {result['triple_count']}/{result['total_triples']}ê°œ")
            
            # ê° Tripleë³„ ìƒì„¸ ì •ë³´ ì¶œë ¥
            if 'satisfied_triples' in result:
                print("   ë§¤ì¹­ëœ Triple ìƒì„¸:")
                for j, triple_result in enumerate(result['satisfied_triples']):
                    q_idx = triple_result['query_idx']
                    if q_idx < len(triples):
                        triple_str = " | ".join(str(t) for t in triples[q_idx])
                        print(f"     â€¢ Triple {j+1}: {triple_str}")
                        print(f"       ìœ ì‚¬ë„: {triple_result['avg_similarity']:.3f}")
                        # Subject ì •ë³´ ì¶œë ¥
                        subject_info = triple_result.get('subject_info')
                        if subject_info:
                            subject_type = subject_info.get('type_of', 'Unknown')
                            subject_super = subject_info.get('super_type', 'Unknown')
                            print(f"       Subject: {triple_result['subject_id']} - {subject_type} ({subject_super}) (ìœ ì‚¬ë„: {triple_result['subject_similarity']:.3f})")
                        else:
                            # Subject ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš°, Eventì˜ subject_idë§Œ í‘œì‹œ
                            print(f"       Subject: {triple_result['subject_id']} (ìœ ì‚¬ë„: {triple_result['subject_similarity']:.3f}) - ë§¤ì¹­ ì‹¤íŒ¨")
                        
                        # Event ë…¸ë“œì¸ ê²½ìš°
                        if 'event_id' in triple_result:
                            print(f"       Verb: {triple_result['event_id']} - {triple_result['verb']} (ìœ ì‚¬ë„: {triple_result['event_similarity']:.3f})")
                        # Spatial ë…¸ë“œì¸ ê²½ìš°
                        elif 'spatial_id' in triple_result:
                            print(f"       Predicate: {triple_result['spatial_id']} - {triple_result['predicate']} (ìœ ì‚¬ë„: {triple_result['predicate_similarity']:.3f})")
                        # Subject-Objectë§Œ ìˆëŠ” ê²½ìš°
                        elif triple_result.get('type') == 'subject_object_only':
                            print(f"       Type: Subject-Object ë§¤ì¹­ (Predicate ì—†ìŒ)")
                        
                        if triple_result['object_id']:
                            obj_sim = triple_result.get('object_similarity')
                            object_info = triple_result.get('object_info')
                            if object_info:
                                object_type = object_info.get('type_of', 'Unknown')
                                object_super = object_info.get('super_type', 'Unknown')
                                if obj_sim is not None:
                                    print(f"       Object: {triple_result['object_id']} - {object_type} ({object_super}) (ìœ ì‚¬ë„: {obj_sim:.3f})")
                                else:
                                    print(f"       Object: {triple_result['object_id']} - {object_type} ({object_super}) (ìœ ì‚¬ë„: N/A)")
                            else:
                                if obj_sim is not None:
                                    print(f"       Object: {triple_result['object_id']} (ìœ ì‚¬ë„: {obj_sim:.3f})")
                                else:
                                    print(f"       Object: {triple_result['object_id']} (ìœ ì‚¬ë„: N/A)")
                        else:
                            print(f"       Object: None")
            else:
                # ê¸°ì¡´ í˜•ì‹ ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
                print(f"   í‰ê·  ìœ ì‚¬ë„: {result.get('avg_similarity', 0):.3f}")
                if 'subject_id' in result:
                    print(f"   Subject: {result['subject_id']}")
                    print(f"   Verb: {result['event_id']} - {result['verb']}")
                    if result.get('object_id'):
                        print(f"   Object: {result['object_id']}")
    
    def hybrid_search(self, query_text: str, query_embedding: List[float], node_type: str = None, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ë²¡í„°)
        
        Args:
            query_text: ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
            query_embedding: ê²€ìƒ‰í•  ë²¡í„° (384ì°¨ì›)
            node_type: ë…¸ë“œ íƒ€ì… í•„í„°
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            search_data = {
                "query_text": query_text,
                "query_embedding": query_embedding,
                "node_type": node_type,
                "top_k": top_k
            }
            
            response = self.session.post(f"{self.db_api_base_url}/search/hybrid", json=search_data)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    # ==================== ë°ì´í„° í™•ì¸ ë° ê´€ë¦¬ ====================
    
    def check_all_data(self) -> None:
        """ëª¨ë“  ì €ì¥ëœ ë°ì´í„° í™•ì¸"""
        self.checker.check_all_data()
    
    def get_schema_info(self) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        self.schema_checker.print_schema_summary()
    
    def get_foreign_keys(self) -> List[Dict[str, Any]]:
        """ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ì •ë³´ ì¡°íšŒ"""
        return self.schema_checker.get_foreign_keys()
    
    def get_table_info(self) -> List[Dict[str, Any]]:
        """í…Œì´ë¸” ê¸°ë³¸ ì •ë³´ ì¡°íšŒ"""
        return self.schema_checker.get_table_info()
    
    def get_column_info(self, table_name: str = None) -> List[Dict[str, Any]]:
        """ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ"""
        return self.schema_checker.get_column_info(table_name)
    
    def get_index_info(self) -> List[Dict[str, Any]]:
        """ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        return self.schema_checker.get_index_info()
    
    def get_data_summary(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        try:
            videos = self.get_videos()
            total_scenes = 0
            total_objects = 0
            total_events = 0
            total_embeddings = 0
            
            for video in videos:
                scenes = self.get_scenes(video['id'])
                total_scenes += len(scenes)
                
                for scene in scenes:
                    objects = self.get_scene_objects(scene['id'])
                    events = self.get_scene_events(scene['id'])
                    embeddings = self.get_scene_embeddings(scene['id'])
                    
                    total_objects += len(objects)
                    total_events += len(events)
                    total_embeddings += len(embeddings)
            
            return {
                "total_videos": len(videos),
                "total_scenes": total_scenes,
                "total_objects": total_objects,
                "total_events": total_events,
                "total_embeddings": total_embeddings,
                "videos": videos
            }
        except Exception as e:
            print(f"âŒ ë°ì´í„° ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    # ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ====================
    
    def _generate_video_id(self, drama_name: str, episode_number: str) -> int:
        """ë¹„ë””ì˜¤ ê³ ìœ  ID ìƒì„± (32ë¹„íŠ¸ ì •ìˆ˜ ë²”ìœ„ ë‚´)"""
        # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ID ìƒì„± (32ë¹„íŠ¸ ì •ìˆ˜ ë²”ìœ„ ë‚´)
        import hashlib
        content = f"{drama_name}_{episode_number}"
        hash_obj = hashlib.md5(content.encode())
        # 32ë¹„íŠ¸ ì •ìˆ˜ ë²”ìœ„: -2,147,483,648 ~ 2,147,483,647
        # ì–‘ìˆ˜ ë²”ìœ„: 0 ~ 2,147,483,647
        return int(hash_obj.hexdigest()[:7], 16) % 2000000000  # 20ì–µ ë¯¸ë§Œìœ¼ë¡œ ì œí•œ
    
    def export_scene_data(self, scene_id: int, output_file: str = None) -> bool:
        """
        ì¥ë©´ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
        
        Args:
            scene_id: ì¥ë©´ ID
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: scene_{scene_id}.json)
        
        Returns:
            bool: ë‚´ë³´ë‚´ê¸° ì„±ê³µ ì—¬ë¶€
        """
        try:
            scene_data = self.get_scene_graph(scene_id)
            if not scene_data:
                print(f"âŒ ì¥ë©´ {scene_id} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            if output_file is None:
                output_file = f"scene_{scene_id}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(scene_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ì¥ë©´ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_file}")
            return True
        except Exception as e:
            print(f"âŒ ì¥ë©´ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return False
    
    def import_scene_data(self, json_file_path: str) -> bool:
        """
        JSON íŒŒì¼ì—ì„œ ì¥ë©´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            json_file_path: JSON íŒŒì¼ ê²½ë¡œ
        
        Returns:
            bool: ê°€ì ¸ì˜¤ê¸° ì„±ê³µ ì—¬ë¶€
        """
        return self.upload_scene_graph(json_file_path)
    
    # ==================== ëŒ€í™”í˜• ëª¨ë“œ ====================
    
    def interactive_mode(self) -> None:
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        print("ğŸ­ ì¥ë©´ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸")
        print("=" * 50)
        
        while True:
            print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
            print("1. ë°ì´í„° í™•ì¸ (check)")
            print("2. ë¹„ë””ì˜¤ ëª©ë¡ (list)")
            print("3. ë¹„ë””ì˜¤ ì‚­ì œ (delete)")
            print("4. ì¥ë©´ê·¸ë˜í”„ ì—…ë¡œë“œ (upload)")
            print("5. ë°ì´í„° ìš”ì•½ (summary)")
            print("6. ìŠ¤í‚¤ë§ˆ ì •ë³´ (schema)")
            print("7. ì¢…ë£Œ (quit)")
            
            choice = input("\nëª…ë ¹ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”: ").strip().lower()
            
            if choice == 'check':
                self.check_all_data()
            elif choice == 'list':
                self.list_videos()
            elif choice == 'delete':
                self._interactive_delete()
            elif choice == 'upload':
                self._interactive_upload_new()
            elif choice == 'summary':
                self._show_summary()
            elif choice == 'schema':
                self.get_schema_info()
            elif choice in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            else:
                print("âŒ ì˜ëª»ëœ ëª…ë ¹ì–´ì…ë‹ˆë‹¤.")
    
    def _interactive_delete(self) -> None:
        """ëŒ€í™”í˜• ì‚­ì œ ëª¨ë“œ"""
        self.list_videos()
        try:
            video_id = int(input("ì‚­ì œí•  ë¹„ë””ì˜¤ì˜ ê³ ìœ  IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            confirm = input("ì •ë§ë¡œ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ").strip().lower() == 'yes'
            self.delete_video(video_id, confirm)
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _interactive_upload_new(self) -> None:
        """ëŒ€í™”í˜• ì—…ë¡œë“œ ëª¨ë“œ"""
        print("ğŸ“¤ ì¥ë©´ê·¸ë˜í”„ íŒŒì¼ ì—…ë¡œë“œ")
        print("JSON íŒŒì¼ê³¼ ëŒ€ì‘í•˜ëŠ” PT íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
        
        json_file = input("JSON íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if not json_file:
            print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        if not os.path.exists(json_file):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
            return
        
        # íŒŒì¼ ì—…ë¡œë“œ ìˆ˜í–‰
        print(f"\nğŸš€ ì—…ë¡œë“œ ì‹œì‘: {json_file}")
        success = self.upload_scene_graph(json_file)
        
        if success:
            print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ!")
        else:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨!")
    

    def _show_summary(self) -> None:
        """ë°ì´í„° ìš”ì•½ í‘œì‹œ"""
        summary = self.get_data_summary()
        if summary:
            print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìš”ì•½:")
            print(f"  - ë¹„ë””ì˜¤: {summary['total_videos']}ê°œ")
            print(f"  - ì¥ë©´: {summary['total_scenes']}ê°œ")
            print(f"  - ê°ì²´: {summary['total_objects']}ê°œ")
            print(f"  - ì´ë²¤íŠ¸: {summary['total_events']}ê°œ")
            print(f"  - ì„ë² ë”©: {summary['total_embeddings']}ê°œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    client = SceneGraphDBClient()
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "check":
            client.check_all_data()
        elif command == "list":
            client.list_videos()
        elif command == "summary":
            client._show_summary()
        elif command == "schema":
            client.get_schema_info()
        elif command == "search":
            if len(sys.argv) > 2:
                query = sys.argv[2]
                top_k = int(sys.argv[3]) if len(sys.argv) > 3 else 5
                tau = float(sys.argv[4]) if len(sys.argv) > 4 else 0.30
                
                print(f"ğŸ” ê²€ìƒ‰: '{query}' (top_k={top_k}, tau={tau})")
                result = client.vector_search(query, top_k, tau)
                
                if result['success']:
                    print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! {len(result['search_results'])}ê°œ ê²°ê³¼")
                    client.print_search_results(result['search_results'], result['triples'])
                else:
                    print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            else:
                print("ì‚¬ìš©ë²•: python scene_graph_client.py search \"ì§ˆë¬¸\" [top_k] [tau]")
        elif command == "upload":
            if len(sys.argv) > 2:
                json_file = sys.argv[2]
                print(f"ğŸ“¤ ì—…ë¡œë“œ: {json_file}")
                success = client.upload_scene_graph(json_file)
                
                if success:
                    print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ!")
                else:
                    print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨!")
            else:
                print("ì‚¬ìš©ë²•: python scene_graph_client.py upload \"json_file_path\"")
        elif command == "interactive":
            client.interactive_mode()
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python scene_graph_client.py check        # ë°ì´í„° í™•ì¸")
            print("  python scene_graph_client.py list         # ë¹„ë””ì˜¤ ëª©ë¡")
            print("  python scene_graph_client.py summary      # ë°ì´í„° ìš”ì•½")
            print("  python scene_graph_client.py schema       # ìŠ¤í‚¤ë§ˆ ì •ë³´")
            print("  python scene_graph_client.py upload \"json_file\"  # íŒŒì¼ ì—…ë¡œë“œ")
            print("  python scene_graph_client.py search \"ì§ˆë¬¸\" [top_k] [tau]  # ë²¡í„° ê²€ìƒ‰")
            print("  python scene_graph_client.py interactive  # ëŒ€í™”í˜• ëª¨ë“œ")
    else:
        # ê¸°ë³¸ì ìœ¼ë¡œ ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
        client.interactive_mode()


if __name__ == "__main__":
    main()
