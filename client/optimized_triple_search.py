#!/usr/bin/env python3
"""
ìµœì í™”ëœ Triple ê²€ìƒ‰ êµ¬í˜„
ê¸°ì¡´ _search_triples_in_db ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ ê°œì„ í•œ ë²„ì „
"""

import torch
import torch.nn.functional as F
import heapq
from typing import Dict, List, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer
from scene_graph_client import SceneGraphDBClient

class OptimizedTripleSearcher:
    """
    ìµœì í™”ëœ Triple ê²€ìƒ‰ í´ë˜ìŠ¤
    - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
    - ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
    """
    
    def __init__(self, client: SceneGraphDBClient, device: str = "auto"):
        self.client = client
        self.device = device if device != "auto" else ("cuda" if torch.cuda.is_available() else "cpu")
        self.sbert = None
        self.rgcn_embedder = None
        
    def _initialize_models(self, use_rgcn: bool = True):
        """ëª¨ë¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        if self.sbert is None:
            BERT_NAME = "sentence-transformers/all-MiniLM-L6-v2"
            self.sbert = SentenceTransformer(BERT_NAME, device=self.device).eval()
            
        if use_rgcn and self.rgcn_embedder is None:
            try:
                from rgcn_model import RGCNEmbedder
                self.rgcn_embedder = RGCNEmbedder(
                    model_path="model/embed_triplet_struct_ver1+2/best_model.pt",
                    edge_map_path="config/graph/edge_type_map.json",
                    sbert_model="sentence-transformers/all-MiniLM-L6-v2",
                    device=self.device
                )
                print("âœ… R-GCN ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ R-GCN ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨, SBERTë§Œ ì‚¬ìš©: {e}")
                use_rgcn = False
                
        return use_rgcn
    
    def search_triples_optimized(self, triples: List[List[str]], tau: float = 0.30, top_k: int = 5, use_rgcn: bool = True) -> List[Dict[str, Any]]:
        """
        ìµœì í™”ëœ Triple ê²€ìƒ‰
        
        Args:
            triples: ê²€ìƒ‰í•  triple ë¦¬ìŠ¤íŠ¸
            tau: ìœ ì‚¬ë„ ì„ê³„ê°’
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            use_rgcn: R-GCN ê·¸ë˜í”„ ì„ë² ë”© ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # ëª¨ë¸ ì´ˆê¸°í™”
            use_rgcn = self._initialize_models(use_rgcn)
            
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
            print(f"ğŸ” {len(triples)}ê°œ triple ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embeddings = self._embed_triples_batch(triples, use_rgcn)
            
            # 2. DBì—ì„œ ì¥ë©´ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì¡°íšŒ
            print(f"ğŸ” DBì—ì„œ ì¥ë©´ ë°ì´í„° ì¡°íšŒ ì¤‘...")
            scene_data = self._fetch_scene_data_batch()
            
            # 3. ë²¡í„°í™”ëœ ê²€ìƒ‰ ìˆ˜í–‰
            print(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
            results = self._perform_vectorized_search(
                query_embeddings, scene_data, tau, top_k
            )
            
            print(f"âœ… ìµœì í™”ëœ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            print(f"âŒ ìµœì í™”ëœ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _embed_triples_batch(self, triples: List[List[str]], use_rgcn: bool) -> List[Tuple[torch.Tensor, ...]]:
        """Tripleë“¤ì„ ë°°ì¹˜ë¡œ ì„ë² ë”©"""
        embeddings = []
        
        @torch.no_grad()
        def vec(txt: str) -> torch.Tensor:
            return self.sbert.encode(txt, normalize_embeddings=True, convert_to_tensor=True).float()
        
        def token_to_sentence(tok: str | None) -> str:
            if not tok:
                return ""
            sup, typ = tok.split(":", 1) if ":" in tok else (tok, tok)
            return f"A {typ} which is a kind of {sup}."
        
        for i, triple in enumerate(triples):
            s_tok, v_tok, o_tok = (triple + [None, None])[:3]
            
            try:
                if use_rgcn and self.rgcn_embedder:
                    # R-GCN ì„ë² ë”©
                    q_s, q_v, q_o = self.rgcn_embedder.embed_triple_with_rgcn(s_tok, v_tok, o_tok)
                else:
                    # SBERT ì„ë² ë”©
                    q_s = vec(token_to_sentence(s_tok)) if s_tok and s_tok != "None" else None
                    q_v = vec(v_tok) if v_tok and v_tok != "None" else None
                    q_o = (
                        vec(token_to_sentence(o_tok))
                        if o_tok and o_tok not in (None, "", "none", "None") else None
                    )
                
                embeddings.append((q_s, q_v, q_o))
                
            except Exception as e:
                print(f"  âŒ Triple {i+1} ì„ë² ë”© ì‹¤íŒ¨: {e}")
                # Fallback to SBERT
                try:
                    q_s = vec(token_to_sentence(s_tok)) if s_tok and s_tok != "None" else None
                    q_v = vec(v_tok) if v_tok and v_tok != "None" else None
                    q_o = (
                        vec(token_to_sentence(o_tok))
                        if o_tok and o_tok not in (None, "", "none", "None") else None
                    )
                    embeddings.append((q_s, q_v, q_o))
                except Exception as e2:
                    print(f"  âŒ Fallbackë„ ì‹¤íŒ¨: {e2}")
                    embeddings.append((None, None, None))
        
        return embeddings
    
    def _fetch_scene_data_batch(self) -> List[Dict[str, Any]]:
        """ì¥ë©´ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì¡°íšŒ"""
        scene_data = []
        
        try:
            videos = self.client.get_videos()
            print(f"âœ… ë¹„ë””ì˜¤ {len(videos)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            
            for video in videos:
                scenes = self.client.get_scenes(video['id'])
                print(f"âœ… ë¹„ë””ì˜¤ {video['id']}: ì¥ë©´ {len(scenes)}ê°œ")
                
                for scene in scenes:
                    scene_id = scene['id']
                    
                    # ì¥ë©´ì˜ ëª¨ë“  ë…¸ë“œ ë°ì´í„° ì¡°íšŒ
                    objects = self.client.get_scene_objects(scene_id)
                    events = self.client.get_scene_events(scene_id)
                    spatial = self.client.get_scene_spatial_relations(scene_id)
                    temporal = self.client.get_scene_temporal_relations(scene_id)
                    embeddings = self.client.get_scene_embeddings(scene_id)
                    
                    # ì„ë² ë”©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    embedding_dict = {}
                    for emb in embeddings:
                        embedding_data = emb['embedding']
                        if isinstance(embedding_data, str):
                            try:
                                import ast
                                embedding_list = ast.literal_eval(embedding_data)
                                embedding_tensor = torch.tensor(embedding_list, dtype=torch.float32)
                            except Exception:
                                continue
                        elif isinstance(embedding_data, list):
                            embedding_tensor = torch.tensor(embedding_data, dtype=torch.float32)
                        else:
                            embedding_tensor = embedding_data
                        embedding_dict[emb['node_id']] = embedding_tensor
                    
                    # ì¥ë©´ì˜ triple ìƒì„±
                    scene_triples = []
                    for event in events:
                        subject_id = event['subject_id']
                        event_id = event['event_id']
                        object_id = event.get('object_id')
                        verb = event['verb']
                        
                        if (subject_id in embedding_dict and 
                            event_id in embedding_dict and 
                            (object_id is None or object_id in embedding_dict)):
                            subject_emb = embedding_dict[subject_id]
                            event_emb = embedding_dict[event_id]
                            object_emb = embedding_dict.get(object_id) if object_id else None
                            scene_triples.append((subject_emb, event_emb, object_emb, verb))
                    
                    if scene_triples:
                        scene_data.append({
                            'scene_id': scene_id,
                            'video_id': video['id'],
                            'drama_name': video['drama_name'],
                            'episode_number': video['episode_number'],
                            'scene_number': scene['scene_number'],
                            'triples': scene_triples
                        })
            
            print(f"âœ… ì´ {len(scene_data)}ê°œ ì¥ë©´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return scene_data
            
        except Exception as e:
            print(f"âŒ ì¥ë©´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _perform_vectorized_search(self, query_embeddings: List[Tuple[torch.Tensor, ...]], 
                                 scene_data: List[Dict[str, Any]], 
                                 tau: float, top_k: int) -> List[Dict[str, Any]]:
        """ë²¡í„°í™”ëœ ê²€ìƒ‰ ìˆ˜í–‰"""
        heap = []
        total_queries = len(query_embeddings)
        
        for scene_info in scene_data:
            scene_triples = scene_info['triples']
            matched = []
            used = set()
            
            for q_idx, (q_s, q_v, q_o) in enumerate(query_embeddings):
                if q_s is None and q_v is None and q_o is None:
                    continue
                    
                # ì¿¼ë¦¬ ì„ë² ë”©ì„ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                q_s = q_s.to(self.device) if q_s is not None else None
                q_v = q_v.to(self.device) if q_v is not None else None
                q_o = q_o.to(self.device) if q_o is not None else None
                best = None
                
                for subject_emb, event_emb, object_emb, verb in scene_triples:
                    # ê°ì²´ í•„ìˆ˜ ì—¬ë¶€ íŒë‹¨
                    need_obj = q_o is not None
                    if need_obj and object_emb is None:
                        continue
                    
                    # ì„ë² ë”© ë²¡í„° ê°€ì ¸ì˜¤ê¸°
                    v_s = subject_emb.to(self.device)
                    v_v = event_emb.to(self.device)
                    v_o = object_emb.to(self.device) if object_emb is not None else None
                    
                    # ì •ê·œí™”
                    v_s = F.normalize(v_s.unsqueeze(0), dim=1).squeeze(0)
                    v_v = F.normalize(v_v.unsqueeze(0), dim=1).squeeze(0)
                    if v_o is not None:
                        v_o = F.normalize(v_o.unsqueeze(0), dim=1).squeeze(0)
                    
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    s_sim = float(torch.dot(q_s, v_s)) if q_s is not None else None
                    v_sim = float(torch.dot(q_v, v_v)) if q_v is not None else None
                    o_sim = (
                        float(torch.dot(q_o, v_o))
                        if (q_o is not None and v_o is not None) else None
                    )
                    
                    # ì„ê³„ì¹˜ ê²€ì‚¬
                    if (q_s is not None and s_sim < tau) or \
                       (q_v is not None and v_sim < tau) or \
                       (q_o is not None and o_sim < tau):
                        continue
                    
                    sims = [x for x in (s_sim, v_sim, o_sim) if x is not None]
                    sim = sum(sims) / len(sims)
                    
                    if best is None or sim > best[0]:
                        best = (sim, s_sim, v_sim, o_sim, (subject_id, event_id, object_id))
                
                if best:
                    matched.append((q_idx,) + best)
                    used.add(best[-1])
            
            if not matched:
                continue
            
            # ê²°ê³¼ ì €ì¥
            match_cnt = len(matched)
            avg_sim = sum(m[1] for m in matched) / match_cnt
            
            result = {
                "scene_id": scene_info['scene_id'],
                "video_id": scene_info['video_id'],
                "drama_name": scene_info['drama_name'],
                "episode_number": scene_info['episode_number'],
                "scene_number": scene_info['scene_number'],
                "match_count": match_cnt,
                "avg_similarity": avg_sim,
                "matched_triples": matched,
                "total_queries": total_queries
            }
            
            heapq.heappush(heap, (match_cnt, avg_sim, result))
            if len(heap) > top_k:
                heapq.heappop(heap)
        
        # ê²°ê³¼ ì •ë ¬ ë° ë°˜í™˜
        results = sorted(heap, key=lambda x: (-x[0], -x[1]))
        return [result for _, _, result in results]


def test_optimized_search():
    """ìµœì í™”ëœ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ìµœì í™”ëœ Triple ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        client = SceneGraphDBClient()
        searcher = OptimizedTripleSearcher(client)
        print("âœ… ìµœì í™”ëœ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # API ì„œë²„ ì—°ê²° í™•ì¸
    if not client.health_check():
        print("âŒ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    query = "í‚¤ìŠ¤ í•˜ëŠ” ì¥ë©´ì„ ì°¾ì•„ì¤˜"
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
    
    try:
        # 1. ì§ˆë¬¸ì„ tripleë¡œ ë³€í™˜
        from reference_query_to_triples_converter import QueryToTriplesConverter
        import os
        
        converter = QueryToTriplesConverter(
            qa_template_path="templates/qa_to_triple_template.txt",
            api_key=os.getenv("OPENAI_API_KEY"),
            model="gpt-4o-mini"
        )
        
        triples = converter.convert_question(query)
        if not triples:
            print("âŒ ì§ˆë¬¸ì„ tripleë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… {len(triples)}ê°œ triple ìƒì„± ì™„ë£Œ")
        for i, triple in enumerate(triples, 1):
            print(f"  {i}. {' | '.join(str(t) for t in triple)}")
        
        # 2. ìµœì í™”ëœ ê²€ìƒ‰ ìˆ˜í–‰
        import time
        start_time = time.time()
        
        results = searcher.search_triples_optimized(triples, tau=0.30, top_k=5, use_rgcn=True)
        
        end_time = time.time()
        search_time = end_time - start_time
        
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ (ì†Œìš”ì‹œê°„: {search_time:.2f}ì´ˆ)")
        
        # 3. ê²°ê³¼ ì¶œë ¥
        if results:
            print(f"\nğŸ¬ ê²€ìƒ‰ ê²°ê³¼:")
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result['drama_name']} {result['episode_number']} - ì¥ë©´ {result['scene_number']}")
                print(f"     ë§¤ì¹˜: {result['match_count']}/{result['total_queries']}ê°œ, "
                      f"ìœ ì‚¬ë„: {result['avg_similarity']:.3f}")
        else:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    test_optimized_search()
